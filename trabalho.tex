\documentclass[12pt, openright, oneside, a4paper, brazil]{abntex2}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{nameref}
\usepackage[justification=justified,singlelinecheck=false]{caption}
\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{color}
\usepackage{graphicx}
\usepackage{microtype}
\usepackage[brazilian,hyperpageref]{backref}
\usepackage[alf, abnt-emphasize=bf, abnt-url-package=none, abnt-repeated-title-omit=yes, abnt-full-initials=yes, abnt-etal-list=3, abnt-etal-text=emph]{abntex2cite}
\usepackage{trabalho}
\usepackage{lipsum}
\usepackage{trivfloat}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{caption}

% ---
% DEFINIÇÃO DE CORES
% ---

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% ---
% CONFIGURAÇÕES DE PACOTES
% ---

\lstdefinestyle{custompython}{
	backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{codegreen},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\trivfloat{quadro}
\renewcommand{\listquadroname}{Lista de Quadros}
\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
\renewcommand{\backref}{}
\renewcommand*{\backrefalt}[4]{
	\ifcase #1 %
		Nenhuma citação no texto.%
	\or
		Citado na página #2.%
	\else
		Citado #1 vezes nas páginas #2.%
	\fi}%

\titulo{UMA API WEB ORIENTADA A METADADOS COMO SERVIÇO DE RECOMENDAÇÃO HÍBRIDA}
\autor{Iury Krieger}
\local{\vfill Videira - Santa Catarina}
\data{2017}
\orientador{Msc. Tiago Heineck}
\coorientador{Msc. Wanderson Rigo}
\instituicao{
  Instituto Federal Catarinense - Campus Videira
  \par
  Bacharelado em Ciência da Computação
}
\tipotrabalho{Trabalho de conclusão de curso}
\preambulo{
	Trabalho de conclusão de curso submetido ao Instituto Federal Catarinense - Campus Videira como parte dos requisitos para a obtenção do grau de Bacharel em Ciência da Computação
}
\makeatletter
\hypersetup{
	pdftitle={\@title},
	pdfauthor={\@author},
	pdfsubject={\imprimirpreambulo},
	pdfcreator={LaTeX with abnTeX2},
	pdfkeywords={abnt}{latex}{abntex}{abntex2}{trabalho acadêmico},
	colorlinks=true,       		% false: boxed links; true: colored links
	linkcolor=blue,          	% color of internal links
	citecolor=blue,        		% color of links to bibliography
	filecolor=magenta,      		% color of file links
	urlcolor=blue,
	bookmarksdepth=4
}
\makeatother
\setlength{\parindent}{1.3cm}
\setlength{\parskip}{0.2cm}
\makeindex

\begin{document}
\frenchspacing
\imprimircapa
\imprimirfolhaderosto

\begin{comment}
\begin{folhadeaprovacao}
	\begin{figure}[htb]
		\begin{center}
			\includegraphics{images/logo.png}
		\end{center}
	\end{figure}
	{\ABNTEXchapterfont\large{\textbf{BACHARELADO EM CIÊNCIA DA COMPUTAÇÃO}}}
	\begin{center}
		{\ABNTEXchapterfont\large\imprimirautor}

		\vspace*{\fill}\vspace*{\fill}
		\begin{center}
			\ABNTEXchapterfont\bfseries\Large\imprimirtitulo
		\end{center}
		\vspace*{\fill}
	\end{center}

	Este Trabalho de Conclusão de Curso foi julgado adequado para a obtenção do título de Nome do Título em Nome do Curso, Área de Concentração e aprovada em sua forma final pelo Curso de Nome do Curso

	\assinatura{\textbf{\imprimirorientador} \\ Orientador}
	\assinatura{\textbf{Msc. Marcelo Cendron} \\ Professor Convidado I}
	\assinatura{\textbf{Maurício Ferreira} \\ Professor Convidado II}

	\begin{center}
		\vspace*{0.5cm}
		{\large\imprimirlocal}
		\par
		{\large\imprimirdata}
		\vspace*{1cm}
	\end{center}
\end{folhadeaprovacao}
\end{comment}

\begin{folhadeaprovacao}

  \begin{center}
  \vspace*{-1.2cm}
    {\large\imprimirautor}

    \vspace*{\fill}\vspace*{\fill}\vspace*{\fill}
    {\large\imprimirtitulo}
    \vspace*{\fill}\vspace*{\fill}

    \hspace{.45\textwidth}
    \begin{minipage}{.5\textwidth}
        \imprimirpreambulo
    \end{minipage}%
    \vspace*{\fill}
   \end{center}

  \begin{center}
  	 Videira (SC), 16 de Maio de 2017
  \end{center}

    \vspace{-1cm}

   \assinatura{\begin{center}\vspace{-0.6cm}\imprimirorientador \\
   					   Instituto Federal Catarinense
   					   \end{center}
   	}
   	\assinatura{\begin{center}\vspace{-0.6cm} Msc. Wanderson Rigo \\
   					   Instituto Federal Catarinense
   					   \end{center}
   	}
    \begin{center}
  	\textbf{BANCA EXAMINADORA}
   \end{center}
   \vspace{-1cm}
   \assinatura{\begin{center}\vspace{-0.6cm} Msc. Marcelo Cendron \\
      					   Instituto Federal Catarinense
   					     \end{center}
   }
   \assinatura{\begin{center}\vspace{-0.6cm}Maurício Ferreira \\
       					   Instituto Federal Catarinense
   					    \end{center}
    }

    \vspace*{1cm}

\end{folhadeaprovacao}

\begin{dedicatoria}
	\vspace*{\fill}
	\centering
	\noindent

	\textit{Aos meus pais, professores, mentores, amigos e todas as pessoas que, de alguma maneira, possibilitaram que minha pessoa chegasse até aqui, na forma do meu mais profundo agradecimento, dedico-vos a existência deste trabalho.}

	\vspace*{\fill}
 \end{dedicatoria}

\setlength{\absparsep}{18pt} % ajusta o espaçamento dos parágrafos do resumo
\begin{resumo}

Devido a expansão massiva de dados produzidos e disponíveis na Internet, os usuários estão cada vez mais sobrecarregados de informação, não sabendo distinguir informações realmente úteis. Para sanar este problema, os sistemas de recomendação visam recomendar os itens mais úteis a cada usuário, através de técnicas de \textit{machine learning}. Tais técnicas visam prever a avaliação de um usuário a um item, baseando-se nas avaliações já conhecidas. Este trabalho propõe o desenvolvimento de uma API RESTful de código aberto que recomenda itens a usuários, fazendo uso de um sistema de recomendação híbrido que analisa as estruturas de metadados pré definidas e proporciona recomendações, através do conteúdo do item e da filtragem colaborativa de usuários. Dessa forma é possível fornecer um serviço multipropósito, totalmente personalizável, trazendo uma visão mais precisa dos sistemas de recomendação aos desenvolvedores.

\textbf{Palavras-chaves}: Sistemas de Recomendação. Aprendizado de Máquina. Metadados.
\end{resumo}

\begin{resumo}[Abstract]
\begin{otherlanguage*}{english}

Due to the massive expansion of data produced and available on the Internet, users are increasingly overloaded with information, not knowing how to distinguish really useful ones. To remedy this problem through machine learning techniques, the recommendation systems aim to recommend the most useful items to each user. Such techniques are intended to predict a user's rating of an item, based on previously known ratings. This work proposes the development of a RESTful Open Source API that recommends items to users, making use of a hybrid recommendation system that analyzes pre-defined metadata structures and provides recommendations through item content and collaborative user filtering. In this way it is possible to provide a fully customizable multipurpose service, bringing a more accurate view of the recommendation systems to developers.

\textbf{key-words}: Recommender Systems. Machine Learning. Metadata.
\end{otherlanguage*}
\end{resumo}

% ---
% Lista de quadros
% ---
\counterwithout{quadro}{chapter}
\newpage % Forçar a lista de quadros em uma nova página
\phantomsection % Comando necessário caso o pacote hyperref seja utilizado, visando a corrigir o link
\pdfbookmark[0]{\listofquadros}{lof}
\listofquadros* % Adiciona lista de quadros
\cleardoublepage

% ---
% Lista de figuras
% ---
\pdfbookmark[0]{\listfigurename}{lof}
\listoffigures*
\cleardoublepage

% ---
% Siglas
% ---
\begin{siglas}

	\item[IA]{\textit{Inteligência Artificial}}
	\item[HTTP]{\textit{Hypertext Transfer Protocol}}
	\item[API]{\textit{Application Program Interface}}
	\item[REST]{\textit{Representational State Transfer}}
	\item[JSON]{\textit{Javasript Object Notation}}
	\item[IP]\textit{Internet Protocol}

\end{siglas}

% ---
% Sumário
% ---
\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents*
\textual

\chapter{INTRODUÇÃO} \label{intro}

Com o avanço crescente do campo tecnológico, os computadores vêm desempenhando tarefas antes incumbidas à seres humanos. O poder de computação provou-se muito eficaz ao desempenhar tarefas que possuíssem um padrão possível de se expressar através de um algoritmo, mais ainda, se este padrão fosse repetitivo.

Logo os computadores começaram a desempenhar funções nas mais diversas áreas, desde cálculos matemáticos à manipulação de imagens. Atualmente, das funções desempenhadas pelos computadores, a mais difícil de se reproduzir com precisão é o padrão de raciocínio humano.

Alguns autores defendem que para que um computador atinja tal nível, seria necessário que o mesmo possuísse consciência, assim como os seres humanos. Outros defendem que o raciocínio humano não consegue ser reproduzido, apenas emulado, devido à impossibilidade de se programar uma consciência computacional. Tal área de estudo, que tem como o foco o desenvolvimento de sistemas computacionais rumo a proximidade do método humano, chama-se inteligência artificial \cite{russell2004inteligencia, coppin2015inteligencia}.

Possível ou não, é inegável o avanço da inteligência artificial desde seu início nos primórdios da computação. Algumas tarefas, tais como a atribuição de uma consciência a um sistema computacional, deixaram de ser o foco da área, uma vez que não possuímos a tecnologia para construir sistemas muito mais complexos que os atuais  \cite{russell2004inteligencia}.

Entretanto, a inteligência artificial encontrou-se muito eficaz em outras áreas do método humano, tais como o aprendizado, um dos segmentos mais importantes da área, dentro da inteligência artificial chamado de aprendizado de máquina (\textit{machine learning}) \cite{coppin2015inteligencia}.

Desde os anos 90 a preocupação com o armazenamento e a expansão massiva de dados produzidos já existia, prevendo que usuários ficariam sobrecarregados de informação, não sabendo distinguir o que seria realmente útil \cite{hill1995recommending, adomavicius2005toward}. Na época, uma comunidade virtual de avaliação foi proposta para proporcionar aos usuários o mínimo de esforço ao encontrar informações úteis. Com a evolução da inteligência artificial e das técnicas de machine learning, este trabalho de avaliação e recomendação, antes feito por uma comunidade, hoje é atribuído aos sistemas de recomendação \cite{hill1995recommending}.

Sistemas de recomendação (RSs) são ferramentas de  software e técnicas que provém sugestões de artefatos à usuários. Estes artefatos são definidos como os objetos de valor à serem recomendados \cite{ricci2011introduction}. Atualmente, o interesse em tais sistemas se mantém alto, devido a abundância de aplicações práticas \cite{adomavicius2005toward}, exemplificadas nos casos de \textit{E-commerce} por \citeonline{schafer2001commerce}, além de \citeonline{linden2003amazon}, onde são amplamente utilizados.

Desta forma, sistemas de recomendação vem sendo desenvolvidos para a resolução do problema descrito nas mais diversas áreas \cite{bennett2007netflix, gavalas2014mobile}, desde aplicações hoteleiras como o TripAdvisor até aplicações de entretenimento como a Netflix, além da sua origem nos \textit{E-commerces} citados anteriormente. Muitos destes sistemas são casos de RSs aplicados a itens e finalidades específicas \cite{huang2002graph, brozovsky2007recommender}, onde todo o motor de recomendação segue uma abordagem baseada no padrão que lhe foi dado.

Por outro lado, ao observar aplicações web de sistemas de recomendação, verifica-se a existência de soluções em forma de APIs, tais como o Google Cloud Platform e o Microsoft Cognitive Services, fornecidas como serviços transparentes. Entretanto, estas soluções proprietárias não são incorporadas a aplicação, mas sim utilizadas como serviços externos, dificultando a personalização.

Para sanar estes problemas, este trabalho propõe o desenvolvimento de uma API que proporcione uma visão mais transparente dos sistemas de recomendação, permitindo ao usuário desfrutar das funcionalidades, sem a necessidade de um profundo conhecimento dos detalhes que compõem as diferentes técnicas de recomendação, além dos problemas decorrentes do uso de cada uma das técnicas. Além disso, tal tecnologia será fornecida como um serviço de código aberto, podendo ser utilizada em qualquer ambiente.

Este trabalho está dividido em seis seções. A segunda seção apresenta o referencial teórico necessário para o entendimento total do escopo do trabalho. Na terceira seção são apresentadas as principais características do trabalho proposto, além de compará-lo com outros trabalhos relacionados. Em seguida, a quarta seção apresenta a metodologia a ser utilizada para realização do trabalho proposto na seção anterior. Mais à frente, na seção cinco, será abordado o cronograma a ser empregado para a realização do trabalho e, por fim, na sexta seção são apresentadas as considerações finais.

\section{Objetivos} \label{objectives}

\subsection{Objetivo Geral}

Desenvolver uma API web de código aberto para recomendação híbrida de itens a usuários.

\subsection{Objetivos Específicos}

\begin{itemize}
	\item Fornecer uma documentação das funcionalidades visando futura colaboração da comunidade e utilização por outros desenvolvedores.

	\item Proporcionar a recomendação das propriedades relevantes através das estruturas de metadados fornecidas.
\end{itemize}

\section{Metodologia}

A metodologia deste trabalho está dividida em três seções. Primeiramente serão implementadas todas as funcionalidades descritas na seção \nameref{objectives}. Mais à frente, será feita a validação das funcionalidades implementadas e da eficácia das recomendações. Por fim, serão feitos os ajustes e correções necessárias de acordo com o resultado da validação das funcionalidades implementadas.

\subsection{Implementação}

Inicialmente serão implementados os algoritmos de recomendação híbrida, incluindo o processamento dos metadados fornecidos. Os algoritmos de recomendação resumem a eficácia da API e devem consumir a maior parte do tempo de desenvolvimento.

Ao completar a implementação das técnicas híbridas de sistemas de recomendação, serão implementadas as demais funcionalidades da API. Serão consideradas a identificação e entrada dos metadados, além do formato dos dados de saída.

\subsection{Validação}

Assim que a API esteja em um grau considerado funcional, será feita a validação da eficácia ao recomendar as estruturas fornecidas através de grupos de testes definidos, uma técnica amplamente utilizada na validação de técnicas de machine learning.

A validação será feita utilizando um grupo separado dos  dados utilizados para testes, confrontando as recomendações feitas com o resultado esperado. Através desses resultados é medida a acurácia de um sistema de recomendação, métrica utilizada como medida de eficiência entre os diferentes métodos utilizados.

\subsection{Ajustes e Correções}

Por fim, serão feitos os ajustes e correções de erros recolhidos ao longo do processo, além de testar as funcionalidades e a utilização da API como um todo. A documentação será feita durante boa parte de todo o processo e, neste caso em específico, possui um foco especial, uma vez que o princípio da API é que a mesma seja utilizável por outros desenvolvedores, além de possibilitar a contribuição da comunidade.

\section{Trabalhos Relacionados} \label{related_work}

Tendo como base as técnicas descritas acima, existem trabalhos como os apresentados por \citeonline{guo2015librec}, que abordam as técnicas em forma de biblioteca Java a ser incluída nos projetos. Esta abordagem torna a utilização mais simples devido ao fato do usuário poder utilizar apenas as funcionalidades da biblioteca, preocupando-se com o formato de entrada e saída dos dados, não com o processo de recomendação em si. Outra abordagem interessante é a proposta por \citeonline{brozovsky2007recommender} ao construir uma biblioteca C\# multipropósito, focando na recomendação de itens com base na avaliação em um esquema de \textit{rating} (de uma a cinco estrelas), ou com base apenas em itens com avaliação positiva.

Em relação ao trabalho acima citado, a API proposta neste trabalho também visa ser multipropósito e distribuída como código aberto pela licença pública GNU (\textbf{GPL}), porém, fornecendo tais funcionalidades como um serviço web independente de linguagem de programação, o que não acontece nos exemplos apresentados.

Além dos trabalhos apresentados, \citeonline{do2013filtragem} aborda os sistemas de recomendação com uma perspectiva semelhante a este trabalho, focando mais no ganho de desempenho ao processar o método de filtragem colaborativa na GPU. Este trabalho não tem seu foco em desempenho, mas sim em uma proposta de \textbf{recomendação genérica}, que forneça recomendações a quaisquer modelos de usuários e itens através do método híbrido.

%
%--------- FIM INTRODUÇÃO------------
%

\cleardoublepage

\chapter{REFERENCIAL TEÓRICO}

Visando dissecar todos os conceitos previamente necessários para completo entendimento deste trabalho, este capítulo levanta as principais referencias utilizadas como base para desenvolvimento das soluções propostas no capítulo \ref{intro}. Este capítulo pode ser divido em três partes. Primeiro, a seção \ref{machine_learning} aborda os principais conceitos referentes ao aprendizado de máquina. Em sequência, na seção \ref{recommender_systems} são abordados os diferentes tipos de sistemas de recomendação, suas peculiaridades e limitações. Por fim, a última seção apresenta o padrão RESTful, comumente utilizado na construção de APIs.

\section{Aprendizado de Máquina} \label{machine_learning}

Um dos segmentos da inteligência artificial com grande importância na atualidade é o aprendizado de máquina. Responsável pela construção de agentes capazes de, a partir de uma coleção de pares de entrada e saída, aprender uma função que prevê a saída para novas entradas. Tais agentes são definidos como tudo que pode perceber seu ambiente através de sensores, além de atuar sobre o mesmo através de atuadores. Em outras palavras, o aprendizado de máquina resume-se em técnicas que proporcionam a um algoritmo a capacidade de melhorar seu desempenho de forma automática, através do conhecimento obtido pelas entradas existentes \cite{coppin2015inteligencia}.

Dessa forma, considera-se que um agente está aprendendo se melhorar o seu desempenho nas tarefas para que foi designado, a partir de suas observações sobre o mundo. Este aprendizado proporciona às técnicas de \textit{machine learning} a capacidade evolutiva, uma vez que é possível não só responder as entradas do mundo exterior como também tirar conclusões sobre as mesmas, melhorando cada vez mais a natureza da solução \cite{russell2004inteligencia}.

Conforme apresentado por \citeonline{carbonell1983overview}, devido a capacidade de, além de solucionar problemas, melhorar automaticamente o desempenho da solução, os sistemas de aprendizagem tem suas aplicações nas mais diversas áreas, tais como agricultura, educação, sistemas especialistas de alta performance, reconhecimento de imagem, programação, etc. Através de um apanhado das aplicações nas áreas de utilização, \citeonline{carbonell1983overview} dividem o campo de aprendizado do \textit{machine learning} em três partes:

\begin{itemize}
	\item \textbf{Estudos orientados à tarefa (\textit{Task-oriented studies}):} composto pelo desenvolvimento e análise de sistemas de aprendizagem visando melhorar a performance na solução de determinadas tarefas.

	\item \textbf{Simulação cognitiva (\textit{Cognitive simulation}):} formado pela investigação e simulação do processo de aprendizagem humano.

	\item \textbf{Análise teórica (\textit{Theoretical analysis}):} exploração teórica do espaço de possíveis processos de aprendizado.
\end{itemize}

Analisando a taxonomia proposta por \citeonline{carbonell1983overview}, pode-se identificar que o escopo deste trabalho encontra-se nos estudos orientados à tarefa, onde o propósito é a melhoria da performance, neste caso através de recomendações orientadas à metadados.

Como exemplo do uso das técnicas de \textit{machine learning}, \citeonline{sebastiani2002machine}  apresenta um algoritmo de categorização de texto que, a partir de um conjunto de documentos pré-classificados (entradas), constrói um classificador para novos documentos (novas entradas). Outro exemplo, apresentado por \citeonline{pang2002thumbs}, reforça a ideia de melhora de desempenho para novas entradas através de um padrão aprendido a partir de entradas já existentes. Através de dados sobre avaliações de filmes, pode-se perceber que, mesmo as técnicas padrão de \textit{machine learning}, acabam superando os patamares humanos na classificação de sentimentos.

\section{Sistemas de Recomendação} \label{recommender_systems}

Como ramificação do aprendizado de máquina, os sistemas de recomendação (RSs) são técnicas de software que provém sugestões a usuários de itens que os mesmos possam querer utilizar \cite{resnick1997recommender, schafer1999recommender}. Desta forma, recomendações seriam, em sua forma mais simples, rankings de itens, tais como os utilizados na maioria das soluções de produtos (livros mais lidos, filmes mais assistidos, etc.) \cite{ricci2011introduction}. O que os RSs trazem de novo é a tentativa de predizer, através da filtragem colaborativa ou da similaridade de conteúdo, qual o ranking mais adequado de produtos ou serviços a um usuário. A filtragem colaborativa, termo cunhado por \citeonline{resnick1997recommender}, recomenda itens baseando-se nos relacionamentos do usuário. Por outro lado, a similaridade de conteúdo baseia-se no conteúdo de itens já avaliados pelo usuário. Tais dados podem ser coletadas de forma explícita, na forma de perguntas diretas e avaliações do usuário sobre os itens, ou de forma interpretativa, inferindo sobre ações tomadas pelo usuário e atribuindo peso a elas.

Mais formalmente, os sistemas de recomendação podem ser descritos matematicamente da seguinte forma: sendo \emph{C} o conjunto de todos os usuários e \emph{S} o conjunto de todos os itens que podem ser recomendados, tanto o espaço \emph{S} como o espaço \emph{C} podem ser extremamente grandes, batendo os milhões de usuários e itens \cite{adomavicius2005toward, gomez2016netflix}. Dessa forma, tem-se \textit{u} como a função de utilidade de um item \emph{s} para um usuário c. A função u utiliza-se do conjunto ordenado R, descrito como $C \times S \rightarrow R$, para encontrar o item $\emph{s} \in \emph{S}$ com a maior utilidade para o usuário \emph{c}. Um exemplo de como as preferências são armazenadas no espaço de avaliações C x S pode ser visto no quadro 1.

\begin{quadro}[h!tp]
	\caption{\label{movie_matrix}Exemplo de matriz de recomendações a filmes}
	\begin{center}
		\includegraphics[scale=0.8]{images/movie_matrix.png}
	\end{center}
	\hspace{5.5cm}{Fonte: \citeonline{adomavicius2005toward}}
\end{quadro}

De acordo com o quadro 1, o símbolo $"\emptyset"$ representa os filmes ainda não avaliados pelos usuários. Estes itens, por sua vez, são os alvos das técnicas de recomendação que tentam predizer a avaliação de um usuário. Uma vez que o motor de recomendação pode predizer as avaliações de um usuário, pode-se recomendar ao mesmo apenas os \emph{N} itens com a maior avaliação estimada \cite{adomavicius2005toward}.

Como consequência da importante participação dos sistemas de recomendação em sites com um grande número de público, tais como Netflix, eBay e Amazon.com, os mesmos tornaram-se ferramentas poderosas \cite{schafer1999recommender} e são considerados os propulsores de várias estatísticas, entre elas: o aumento da satisfação dos usuários, devido a precisão das recomendações; o aumento da fidelidade dos usuários, devido ao aumento de precisão quanto maior for a interação do usuário com o site; a aumento da capacidade do próprio serviço em entender melhor as intenções de seu público \cite{ricci2011introduction}. Tendo em vista o crescimento do número de aplicações que utilizam sistemas de recomendação e da variedade de soluções utilizadas em grandes sites, torna-se notável a importância dos mesmos.

Como próximo passo na evolução dos sistemas de recomendação, \citeonline{adomavicius2015context} propõem que os RSs, além de considerarem a similaridade entre perfis, devem estar cientes do contexto da avaliação do usuário ao construírem o modelo de perfil. Chamados de sistemas cientes de contexto, estes sistemas de recomendação devem diferenciar a ação que o usuário toma ao apenas analisar um item (filme, produto, etc.), não necessariamente indicando que itens parecidos devem ser recomendados no futuro, da ação tomada ao consumir um item (comprar, assistir, etc.). A partir dessa distinção de contexto, os RSs poderiam atribuir pesos diferentes para cada ação, podendo assim fazer recomendações mais precisas.

A seguir serão apresentados as diferentes técnicas dos sistemas de recomendação, além de qual técnica será utilizada por este trabalho e seus diferentes métodos através de algoritmos. Devido a existência de inúmeras técnicas e métodos de recomendação, este trabalho abordará apenas as técnicas necessárias para entendimento do mesmo, aprofundando-se apenas nos métodos que compõem a técnica utilizada.

\subsection{Método Baseado em Conteúdo} \label{recs:content_based}

Sistemas de recomendação que implementam o método baseado em conteúdo (\textit{content-based}) analisam um conjunto de documentos/descrições de itens previamente avaliados pelo usuário, construindo um modelo dos interesses baseando-se nas características dos itens avaliados \cite{mladenic1999text, adomavicius2005toward, lops2011content}. Este modelo serve para ser cruzado com o conteúdo de outros itens ainda não avaliados pelo usuário. Quanto maior o grau de semelhança entre o modelo do usuário e as características do item, maior a probabilidade do mesmo ter interesse.

Para que o modelo de interesses do usuário seja criado e confrontado com outros conteúdos ainda não avaliados, são necessários três atores principais que dividem a recomendação baseada em conteúdo: \textbf{analisador de conteúdo}, \textbf{aprendiz de perfis} e \textbf{componente de filtragem} \cite{lops2011content}. A estrutura completa destes agentes pode ser vista na \autoref{content_based}.

\begin{figure}[h!tp]
	\caption{\label{content_based}Arquitetura de um sistema baseado em conteúdo}
	\begin{center}
		\includegraphics[scale=0.75]{images/content_based.png}
	\end{center}
	\hspace{5.5cm}{Fonte: \citeonline{lops2011content}}
\end{figure}

Note que na \autoref{content_based}, a primeira parte do processo começa com o \textbf{analisador de conteúdo} (\textit{content analyzer}), transformando dados não estruturados em estruturas de atributos e características \cite{lops2011content, mladenic1999text}, armazenando-as no repositório de itens representados (\textit{represented items}). Para a construção e atualização do perfil de interesses do usuário ativo (representado na \autoref{content_based} por $u_{a}$), as avaliações do usuário para novos itens são armazenadas no repositório de feedback. O tipo de avaliação depende de cada aplicação, podendo ser expressado de forma \textbf{explícita}, como as avaliações binárias (\textit{like/dislike}) e avaliações em forma de rating (0 a 5; 1 a 5 estrelas) utilizadas em muitos sites, ou mesmo por avaliações \textbf{implícitas}, onde uma ação sobre um item (seleção, por exemplo) possui um peso atribuído \cite{pazzani2007content}.

De posse do repositório de itens representados, o \textbf{aprendiz de perfis} varre os itens $I_{k}$ do usuário ua em prol de construir o conjunto treinamento $TR_{a}$. O conjunto de treinamento é um conjunto de pares $\lbrace I_{k}$, $r_{k} \rbrace$, onde $r_{k}$ é a avaliação dada pelo usuário ua a representação do item $I_{k}$. Após a construção do conjunto de treinamento $TR_{a}$, o \textbf{aprendiz de perfis} aplica algoritmos de aprendizagem supervisionada para gerar o modelo de interesses do usuário $u_{a}$. Os modelos de interesses são armazenados no repositório de perfis (representado na \autoref{content_based} por \textit{profiles}) para uso futuro pelo \textbf{componente de filtragem}.

Quando a representação de um novo item é adicionada ao conjunto de itens representados, o componente de filtragem prediz se o mesmo será de interesse do usuário $u_{a}$, através da comparação entre os atributos e características do novo item e o modelo de interesses do usuário. Em consequência, o componente de filtragem ranqueia os itens com os maiores potenciais de interesse, agrupando-os em uma lista de recomendações $L_{a}$ e apresentando-a ao usuário $u_{a}$. Dessa forma o usuário ua pode prover novas avaliações (\textbf{feedback}) dos itens da lista $L_{a}$, fazendo com que o aprendiz de perfis atualize seu modelo de interesses através da reconstrução do conjunto de treinamento $TR_{a}$ \cite{lops2011content}.

Atualmente \citeonline{pazzani2007content} apresentam que, devido ao grande crescimento de informação disponível para treinamento, os métodos atuais reduzem o conjunto de treinamento para algumas centenas de linhas, porém altamente relevantes (através de técnicas como o TF-IDF \footnote{Frequência do termo inverso da frequência nos documentos. Medida estatística para indicar a importância de uma palavra de um documento em relação a uma coleção de documentos. É frequentemente usada na mineração de dados.}). Dessa forma, por mais que as bases de dados aumentem, o conjunto de treinamento se mantém relevante e não é necessário percorrer todo o conjunto ordenado $R$.

\subsection{Método Baseado em Colaboração} \label{recs:collaborative_based}

O método de filtragem colaborativa (\textit{collaborative-based} - CF) baseia-se no processo de avaliar itens através da opinião de outras pessoas. Tal processo, que começou com a filtragem da natureza de repositórios de texto, passou a ser mais informal, abrangendo até listas de discussão e arquivos de \textit{e-mail}. No começo, usuários tinham que acessar sites específicos, tais como o MovieLens, para receberem recomendações de filmes. Conforme os sistemas baseados em CF foram se popularizando, os sites começaram a utilizar estes sistemas para adequar seu conteúdo para cada usuário \cite{schafer2007collaborative}.

Assim como os sistemas baseados em conteúdo, sistemas de filtragem colaborativa também levam em consideração as avaliações de itens (mesmo que de outros usuários similares), através dos métodos de avaliação já descritos. Segundo \citeonline{adomavicius2005toward}, a diferença entre estes dois processos existe pelo fato de que a utilidade $u(c,s)$ de um item $s$ a um usuário $c$ é medida não pela utilidade $u(c,s_{i})$ dos itens $s_{i}$ similares ao item $s$, mas sim pela utilidade $u(c_{j}, s)$ do item $s$ baseado nos usuários $c_{j}$ \textbf{similares} ao usuário $c$. Em outras palavras, na filtragem colaborativa, os itens considerados úteis a um usuário são os itens úteis a usuários similares a ele.

Partindo desta premissa, \citeonline{sarwar2001item} abordam os sistemas de filtragem colaborativa a partir do seguinte cenário: uma lista de $\textbf{m}$ usuários $U \lbrace u_{1}, u_{2}, …, u_{m} \rbrace$ e uma lista de $\textbf{n}$ itens $I \lbrace i_{1}, i_{2}, …, i_{n} \rbrace$. Cada usuário $u_{i}$ possuindo uma lista $Iu_{i}$ de itens, avaliados ou não. Conforme na \autoref{collaborative_based}, o algoritmo de filtragem colaborativa (\textbf{CF}) opera sobre a matriz de avaliações $n \times m$.

\begin{figure}[htb]
	\caption{\label{collaborative_based}Processo de recomendação colaborativa.}
	\begin{center}
		\includegraphics[scale=0.6]{images/collaborative_based.png}
	\end{center}
	\hspace{5.5cm}{Fonte: \citeonline{sarwar2001item}}
\end{figure}

De posse da matriz $n \times m$, o algoritmo \textbf{CF} faz a predição/recomendação ao usuário corrente, demonstrado na \autoref{collaborative_based} por $u_{a}$. O usuário $u_{a}$ é visto pelo algoritmo como o alvo atual para o qual serão feitas as predições/recomendações. \citeonline{sarwar2001item} também especificam a predição como um valor numérico que expressa a probabilidade prevista do item ser de interesse do usuário $u_{a}$, sendo este um item ainda não pertencente ao conjunto de $Iu_{a}$. Por outro lado, a recomendação é descrita como uma lista de $\textbf{N}$ itens, cada item $I_{r}$ dentre os itens com a maior probabilidade de utilidade ao usuário ua e ainda não avaliados pelo mesmo. Esta forma de recomendação também é conhecida como recomendação \textbf{Top-N} \cite{adomavicius2005toward}.

Diferentemente do método baseado em conteúdo, a filtragem colaborativa não possui apenas uma abordagem. Tanto \apudonline{sarwar2001item}{breese1998empirical} quanto \citeonline{adomavicius2005toward} dividem a filtragem colaborativa em duas ramificações:

\begin{itemize}
	\item \textbf{Baseada em memória (\textit{memory-based})}: implica na utilização de toda a matriz $n \times m$ para obter um conjunto de usuários vizinhos (\textit{neighbor-users}), ou seja, usuários que tendem a avaliar diferentes itens similarmente ou itens similares diferentemente ao usuário $u_{a}$. Ao obter o conjunto, os métodos baseados em memória combinam as preferências dos usuários, fornecendo uma recomendação Top-N ao usuário $u_{a}$.

	\item \textbf{Baseada em modelo (\textit{model-based})}: ao invés de utilizar toda a matriz $n \times m$, esta técnica constrói um modelo das avaliações de cada usuário através de diferentes técnicas de \textit{machine learning}, tais como modelos de \textit{cluster} e redes Bayesianas. Devido a complexidade destas técnicas e das mesmas não pertencerem ao escopo da solução apresentada neste trabalho , não abordaremos mais a fundo seu funcionamento.
\end{itemize}

Dessa forma, sistemas de filtragem colaborativa podem ser usados nos casos em que se deseja recomendar itens úteis a um usuário ou fornecer uma previsão ao usuário da probabilidade do mesmo gostar de um item em particular. Além disso, é possível recomendar ao usuário não só itens, mas também usuários ou grupos de usuários que o mesmo possa gostar, o que não é possível nos sistemas baseados em conteúdo \cite{schafer2007collaborative}.

Considerando tais utilidades, tanto \citeonline{schafer2007collaborative} quanto \citeonline{adomavicius2005toward} expõem os sistemas de recomendação baseados em conteúdo e colaborativos como complementares, uma vez que o método baseado em conteúdo prediz a relevância de itens sem avaliações, enquanto o método colaborativo prediz a relevância através de recomendações alheias. A união destas técnicas, em prol de maximizar a eficiência e compensar as limitações (seção 2.2.4), deu origem ao \textbf{método híbrido} que será abordado a seguir.

\subsection{Método Híbrido}

Sistemas de recomendação híbridos seriam quaisquer sistemas que combinam múltiplas técnicas de recomendação para produzir seu resultado \cite{burke2002hybrid, burke2007hybrid}. Como apresentado por \citeonline{adomavicius2005toward}, as técnicas de recomendação possuem limitações de acordo com a abordagem utilizada. Sendo assim, é possível combinar diferentes técnicas para obter o desempenho e precisão desejadas.

\begin{quadro}[h!tp]
	\caption{\label{recommender_systems}Técnicas de recomendação.}
	\begin{center}
		\includegraphics[scale=0.6]{images/recommender_systems.png}
	\end{center}
	\hspace{5.5cm}{Fonte: \citeonline{burke2002hybrid}}
\end{quadro}

Como pode ser visto no quadro 2, \citeonline{burke2002hybrid} apresenta uma série de métodos de recomendação além dos mais comuns abordados neste trabalho. Estes métodos, combinados entre si, podem gerar sistemas híbridos categorizados da seguinte forma:

\begin{itemize}
	\item \textbf{Atribuição de peso (\textit{Weighted}):} Consiste na atribuição de peso para cada um dos métodos empregados no sistema híbrido. Baseado no histórico de acertos entre um método e outro, é possível ajustar o peso de cada um, dando um peso maior ao método atualmente mais eficiente.

	\item \textbf{Escalonamento (\textit{Switching}):} Consiste na utilização de um critério pré-definido para escolher qual método será utilizado no momento. Por exemplo, se o método colaborativo não fornecer uma recomendação com confiança suficiente, o sistema pode trocar para o método baseado em conteúdo.

	\item \textbf{Misto (\textit{Mixed}):} Consiste em usar tanto recomendações de um método quanto de outro, apresentando os resultados de ambos ao usuário.

	\item \textbf{Combinação de características (\textit{Feature Combination}):} Consiste em utilizar a informação colaborativa apenas como características adicionais no conjunto utilizado pelo método baseado em conteúdo.

 	\item \textbf{Cascata (\textit{Cascade}):} Este método em especial consiste em refinamento por estágio, ou seja, o primeiro método é utilizado para gerar um conjunto de recomendações, enquanto o segundo é responsável por refinar o conjunto gerado e assim por diante.

	\item \textbf{Aumento de Recursos (\textit{Feature Augmentation}):} Esta técnica utiliza a recomendação gerada pelo primeiro método como informação para o processamento do segundo método.

	\item \textbf{Meta-nível (\textit{Meta-level}):} Consiste em utilizar o modelo de saída de um método como entrada para o outro. Diferente do aumento de recursos, nesta técnica todo o modelo gerado pelo primeiro método é utilizado.
\end{itemize}

Tendo em vista a taxonomia apresentada por \citeonline{burke2002hybrid}, nota-se que a recomendação híbrida não refere-se ao funcionamento das recomendações, mas sim sobre como os diferentes métodos \textbf{interagem entre si}. Esta interação pode ser insensível à ordem, nos casos de métodos como a atribuição de peso, misto, escalonamento e combinação de características. Já nas outros métodos apresentados, a ordem de execução dos métodos de recomendação alteram o resultado final, uma vez que a saída de um, direta ou indiretamente é a entrada de outro.

Por exemplo, \citeonline{tran2000hybrid} apresentam uma arquitetura híbrida, utilizando os métodos baseado em colaboração (collaborative-based) e baseado em conhecimento (knowledge-based), ambos exemplificados através da arquitetura ilustrada na \autoref{hybrid_scheme}.

\begin{figure}[h!tp]
	\caption{\label{hybrid_scheme}Exemplo de arquitetura híbrida.}
	\begin{center}
		\includegraphics[scale=0.8]{images/hybrid_scheme.png}
	\end{center}
	\hspace{5.5cm}{Fonte: \citeonline{tran2000hybrid}}
\end{figure}

Como ilustrado na \autoref{hybrid_scheme}, a arquitetura descrita exemplifica um sistema híbrido de escalonamento (\textit{switching}). Sendo assim, dependendo da situação atual, o sistema pode trocar entre a recomendação colaborativa e a baseada em conhecimento, visando prover melhores recomendações. Considerando que inicialmente a abordagem colaborativa não seria muito eficiente, enquanto a base de dados não possui muitos usuários com modelos conhecidos e não existem itens avaliados o suficiente, \citeonline{tran2000hybrid} optaram por escalonar para o método baseado em conhecimento.

Através dessas limiares, toda vez que o usuário requisita uma recomendação, o agente de interface interativa (\textit{interactive interface agent}) verifica se as mesmas já foram atendidas. Se sim, o agente utiliza a recomendação do método de filtragem colaborativa, se não, o método baseado em conhecimento é utilizado.

Tanto \citeonline{balabanovic1997fab} quanto \citeonline{claypool1999combining} utilizam sistemas híbridos compostos de duas técnicas combinadas: \textbf{baseado em conteúdo} e \textbf{baseado em colaboração}. Dessa forma, é possível utilizar o método colaborativo para gerar o conjunto de $\textbf{N}$ usuários vizinhos (\textit{neighbor-users}) já descrita neste trabalho. A partir do conjunto gerado é aplicado o método baseado no conteúdo destes usuários próximos, aumentando a precisão da recomendação gerada.

Ao invés de se utilizar apenas um método, a utilização de sistemas híbridos pode trazer uma série de benefícios: ao executar recomendações baseadas em conteúdo, o sistema colaborativo pode lidar com novos usuários que ainda não tem seu modelo definido; torna-se possível fazer recomendações precisas a um usuário, mesmo que não existam usuários similares ao mesmo; pode-se recomendar itens não avaliados por nenhum dos usuários, cruzando o modelo dos mesmos com o conteúdo do item \cite{balabanovic1997fab}.

Como forma de verificar a eficácia do método híbrido em relação aos métodos utilizados de forma individual, \citeonline{claypool1999combining} utilizam como métrica a inexatidão, sendo o termo referente a discrepância entre a recomendação obtida e o resultado esperado. A inexatidão dos métodos em relação a seu tempo de utilização pode ser visto através do resultado ilustrado na \autoref{innacurace}.

\begin{figure}[h!tp]
	\caption{\label{innacurace}Inexatidão entre os métodos de recomendação.}
	\begin{center}
		\includegraphics[scale=0.8]{images/innacurace.png}
	\end{center}
	\hspace{5.5cm}{Fonte: \citeonline{claypool1999combining}}
\end{figure}

Analisando a \autoref{innacurace} pode-se verificar que nos primeiros dias, a inexatidão do método colaborativo era maior devido a falta de completude no modelo dos usuários, construído por meio de usuários que ainda não avaliaram itens, ou de usuários que não se beneficiam da opinião de outros \cite{claypool1999combining}. Conforme o método colaborativo foi estabelecendo relações entre os usuários, este ficou mais preciso e o método baseado em conteúdo começou a ser menos viável. Porém, independente dos picos de inexatidão dos métodos separados mostrados na \autoref{innacurace}, quando combinados (\textbf{recomendação híbrida}), é possível notar uma constância muito maior, possuindo o mais baixo nível de inexatidão em todos os momentos.

Em resumo os sistemas híbridos foram criados para unir técnicas de recomendação com objetivo de \textbf{compensar as limitações} apresentadas pela utilização dessas mesmas técnicas individualmente \cite{balabanovic1997fab}. Tais limitações e seus efeitos no resultado das recomendações serão abordadas na seção a seguir.

\subsection{Limitações}

Conforme apresentado por \citeonline{adomavicius2005toward}, decorrente da utilização das técnicas acima descritas, tanto os sistemas baseados em conteúdo quanto os sistemas colaborativos possuem limitações. Estas limitações, motivo da criação dos sistemas híbridos \cite{balabanovic1997fab}, possuem características claras de acordo com o tipo de recomendação utilizado, sendo divididas da seguinte maneira:

\begin{itemize}
	\item \textbf{Análise de conteúdo limitada (\textit{limited content analysis}):} presente nas técnicas baseadas em conteúdo, devido as mesmas serem limitadas por uma quantidade específica de características relevantes para a recomendação. Além disso, essas características precisam ser extraídas de forma explícita, o que dificulta muito a extração de atributos através de conteúdo como vídeo, imagem, etc.

	\item \textbf{Problema do novo usuário (\textit{new user problem}):} comum nas técnicas que utilizam as preferências do usuário como métrica, consiste no fato de que um usuário precisa ter um número suficiente de avaliações para que o sistema entenda suas preferências e forneça recomendações precisas.

	\item \textbf{Superespecialização (\textit{over-specialization}):} comum nas técnicas de recomendação baseada em conteúdo, consiste no fato de que se o sistema apenas recomenda ao usuário itens semelhantes aos que ele já avaliou de forma positiva, o usuário será limitado à apenas recomendações de itens já avaliados, reduzindo cada vez mais a recomendação de novos itens.

	\item \textbf{Problema do novo item (\textit{new item problem}):} sistemas colaborativos baseiam-se apenas nas preferências dos usuários para fazer as recomendações. Sendo assim, novos itens que ainda não foram avaliados por nenhum usuário não serão recomendados.

	\item \textbf{Esparsidade (\textit{Sparsity}):} quando um item é raramente recomendado devido a sua esparsidade no conjunto de usuários e itens, ou seja, um item que é pouco recomendado pelos usuários tende a ser cada vez menos recomendado em sistemas colaborativos, devido ao pouco número de avaliações que o mesmo possui.
\end{itemize}

Sendo assim, grande parte das pesquisas relacionadas a sistemas de recomendação tem como objetivo principal melhorar a precisão das técnicas, reduzindo o impacto das limitações descritas. Porém, como apresentado por \citeonline{mcnee2006being}, nem sempre os itens mais precisos em relação às métricas de cada método são os mais úteis aos usuários.

Considerando que os sistemas de recomendação usualmente abordam apenas algumas, das muitas métricas que definem a utilidade de um item ao usuário, \citeonline{mcnee2006being} ressaltam que cada vez mais a utilização de sistemas de recomendação leva a construção de um conjunto de itens muito similar. Isso ocorre pois quando um usuário avalia um item, as próximas recomendações levarão o mesmo em consideração, recomendando itens cada vez mais parecidos com o item avaliado. Este processo acaba gerando o que \citeonline{mcnee2006being} definem como “\textbf{buraco de similaridade}”, onde o sistema tende a fazer apenas recomendações excepcionalmente similares.

\subsection{O Padrão RESTful}

[TODO] Padrão RESTful.

%
%--------- FIM REFERENCIAL TEORICO------------
%

\chapter{API DE RECOMENDAÇÃO ORIENTADA À METADADOS}

Amparado pelos benefícios da utilização de mais de um método de recomendação, apresentando-os em forma de serviço, este capítulo detalha o funcionamento de uma \textbf{API como interface de recomendação}, fazendo uso de metadados provenientes do próprio usuário para criação, validação e interconexão entre as recomendações.

Como parte introdutória ao funcionamento, a seção \nameref{visao_geral} traça de forma abstrata as funcionalidades da API, apresentando os principais componentes e sua correlação. Posteriormente, nas seções \nameref{analisador}, \nameref{motor} e \nameref{interface}, tais funcionalidades são dissecadas de forma diminuir o nível de abstração. Por fim, os testes efetuados e as facilidades implementadas para a utilização da solução são abordados na seção \nameref{testes}.

\section{Visão Geral} \label{visao_geral}

A solução construída tem como função recomendar quaisquer itens a quaisquer usuários, sendo estes provenientes de uma fonte externa, fornecidos pelo usuário da API, nos padrões definidos pelos respectivos \textbf{metadados} existentes, também fornecidos inicialmente pelo usuário da API.

O usuário da API é definido como qualquer agente que tenha interações com a aplicação, humano ou programa, através requisições aos \textit{endpoints} fornecidos na documentação. Essas interações são acordadas pelo protocolo HTTP, usado como base em uma arquitetura RESTful \cite{rodriguez2008restful}. Dessa forma, o usuário da API pode utilizar qualquer interface que suporte o protocolo HTTP para desfrutar das funcionalidades da API, tornando-a multiplataforma e independente de bibliotecas de linguagens de programação específicas. As interações com os recursos da aplicação são efetuadas através dos seguintes métodos do protocolo HTTP:

\begin{itemize}
	\item \textbf{GET}: Interações que demandam a consulta de recursos.

	\item \textbf{POST}: Interações que demandam a criação de novos recursos.

	\item \textbf{PUT}: Interações que demandam a alteração de recursos existentes.

	\item \textbf{DELETE}: Interações que demandam a remoção ou desativação de recursos existentes.
\end{itemize}

Após o envio, a requisição é processada pela interface de usuário da API e, posteriormente, um retorno de sucesso ou erro finaliza a requisição. Para verificar o tipo do retorno da requisição, o usuário da API deve se ater aos \textit{status code} retornados pela API. Em caso de sucesso, por exemplo, a API retornaria um conteúdo JSON relacionado a requisição original e um \textit{status code} da faixa \textbf{2XX}. Já em caso de erro, a API retornaria um conteúdo de erro, anexo a um \textit{status code} da faixa \textbf{4XX} \cite{fielding1999hypertext}. Exemplos de requisição à API e o fluxo das mesmas após o envio podem ser visualizados nas figuras \ref{fetch_api}, \ref{postman} e \ref{interconnection}.

\begin{figure}[htp]
	\caption{\label{fetch_api}Exemplo de adição de item via \textit{fetch} API.}
	\begin{center}
		\includegraphics[scale=0.8]{images/fetch_api.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

\begin{figure}[htp]
	\caption{\label{postman}Exemplo de adição de item via Postman.}
	\begin{center}
		\includegraphics[scale=0.85]{images/postman.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

\begin{figure}[htp]
	\caption{\label{interconnection}Exemplo de fluxo de uma requisição à API.}
	\begin{center}
		\includegraphics[scale=0.62]{images/interconnection.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

A figura \ref{interconnection} mostra um exemplo de requisição à API de recomendação. Nela, são requisitados os \textbf{dez} itens de maior similaridade a serem recomendados para o usuário denominado pelo parâmetro variável \textbf{\textit{user\_id}}. Este processo de requisição e resposta pode ser dividido em quatro partes principais:

\begin{enumerate}
	\item \textbf{Envio}: O usuário da API, devidamente autenticado, escolhe o \textit{endpoint} que corresponde as suas necessidades, enviando uma requisição através dos métodos HTTP previamente citados.

	\item \textbf{Interpretação}: A API receberá a requisição no devido \textit{endpoint}, interpretando-a e repassando-a através de chamadas internas das devidas funcionalidades.

	\item \textbf{Processamento}: Uma vez identificada a ação a ser executada, a API processa os dados (nesse caso as recomendações para o usuário \textbf{\textit{user\_id}}), posteriormente formatando-os em uma estrutura JSON.

	\item \textbf{Retorno personalizado}: Com a estrutura JSON processada em mãos, a API verifica os metadados atuais e retorna, com base nos atributos especificados como visíveis, uma estrutura JSON personalizada pelos desejo do usuário da API.
\end{enumerate}

Partindo da premissa que a solução deve atender modelos genéricos, serão fornecidos na inicialização da API os \textbf{metadados} de usuários, itens e avaliações, correspondendo a estrutura necessária pelo usuário da aplicação. Uma vez que os metadados sejam fornecidos, os dados relacionados devem respeitar as estruturas definidas. Tanto os usuários, itens e avaliações, quanto as futuras recomendações, serão persistidas em um banco de dados, a fim de centralizar as informações e diminuir o tempo de resposta das recomendações requisitadas.

De posse das estruturas de metadados fornecidas na inicialização, o usuário da solução poderá alimentar o sistema através das seguintes interfaces gerais:

\begin{itemize}
	\item \textbf{Metadados}: O usuário da API fornece a estrutura que irá compor cada um dos grupos abaixo. Essas estruturas definem os atributos de cada grupo, o tipo de cada atributo, a importância ou não do atributo nas recomendações, entre outras informações.

	\item \textbf{Usuários}: O usuário da API fornece os usuários aos quais deseja gerar algum tipo de recomendação. Esses dados serão utilizados posteriormente como referência aos itens e para definição da similaridade entre usuários.

	\item \textbf{Itens}: O usuário da API fornece os itens que serão recomendados aos usuários existentes. Os mesmos e seus atributos serão utilizados nas recomendações, atrelados a um usuário em questão.

	\item \textbf{Avaliações}: O usuário da API fornece as avaliações que ligam usuários a itens. Essas informações servem como união, apontando quais usuários estão relacionados a quais itens, sempre atrelando esta relação a uma avaliação numérica.
\end{itemize}

Tais ações de alimentação serão responsáveis por preencher os respectivos conjuntos anteriormente descritos e, a partir deles, construir os modelos de cada usuário e a matriz de avaliações, fundamentais para a geração das recomendações. Durante a requisição de uma recomendação, a solução definirá o método a ser utilizado e o mesmo fará as recomendações com base nos dados conhecidos, respeitando as propriedades descritas nos metadados. Um esquema do funcionamento geral da aplicação pode ser visto na \autoref{overview}.

\begin{figure}[h!tp]
	\caption{\label{overview}Visão geral da API.}
	\begin{center}
		\includegraphics[scale=0.6]{images/MORPY_overview.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

De modo a complementar a visão da API apresentada pela figura \ref{interconnection}, a figura \ref{overview} apresenta o fluxo interno de funcionamento da API, apresentando uma distinção básica entre dois tipos de eventos: os eventos de \textbf{inserção ou atualização de dados} e os eventos de \textbf{geração e requisição de recomendações}. Ambos estão contidos no domínio de atuação da interface de comunicação com o usuário, a qual interpreta as requisições e processa as devidas respostas. Os módulos centrais correspondentes a estes domínios e suas interações podem ser subdivididas nos seguintes:

\begin{itemize}
	\item \textbf{Interface de Comunicação}: É o ponto de contato entre o cliente que utiliza a API e o domínio da aplicação, recebendo todas as requisições nos devidos \textit{endpoints}, processando-as e retornando os resultados. Este módulo é descrito detalhadamente na seção \nameref{interface}.

	\item \textbf{Analisador de Dados}: É o módulo responsável por contrastar as entradas da interface de comunicação com os metadados ativos. O trabalho do analisador de dados é validar o padrão de dados fornecido pelo cliente da API e persistir os dados corretos na base dados, notificando o motor de recomendação sobre quaisquer mudanças. Este módulo é descrito detalhadamente na seção \nameref{analisador}.

	\item \textbf{Motor de Recomendação}: É o módulo que definitivamente faz as recomendações. Ele se alimenta dos dados persistidos pelo analisador, gerando matrizes de relação, utilizadas para calcular o nível de similaridade entre usuário e itens, permitindo a persistência das recomendações na base de dados. Este módulo é descrito detalhadamente na seção \nameref{motor}.
\end{itemize}

Assim que uma requisição é recebida pela interface de comunicação, se a mesma for uma requisição de recomendação, a interface delega ao \textbf{motor de recomendações}, que busca as recomendações persistidas para o usuário em questão. Caso a requisição seja uma alteração de dados existentes, a interface delega ao \textbf{analisador de dados} a tarefa de validar, sempre baseando-se nos metadados atuais, os novos dados providos pelo usuário da API. Assim que esses dados são persistidos na base, o \textbf{motor de recomendações} identifica uma mudança na base e inicia um novo processo paralelo de treinamento para o dado modificado. Dessa forma, quando uma requisição for solicitada, basta o motor de recomendações consultar as recomendações já persistidas.

\section{A Interface de Comunicação} \label{interface}

Visando facilitar a comunicação com o usuário da API através do padrão RESTful, a interface de comunicação tem como principal função ser o ponto de contato entre o agente da requisição e as funcionalidades da API, atendendo a certos padrões de requisição e resposta que serão minuciosamente abordados nesta seção.

Ao passo que a API usa o padrão RESTful como base para a comunicação, é necessário que a mesma utilize um único padrão de dados para que ambos, usuário e API, tenham uma estrutura pré definida de possibilidades de envio e retorno. Dessa forma, o padrão de dados \textbf{JSON}, proposto por \citeonline{crockford2006application} foi o escolhido para servir como representação de dados da API, desde o recebimento de novos recursos (itens, usuários, etc.) até o retorno das recomendações. Um exemplo da representação JSON para as recomendações pode ser visto na figura \ref{json_example}.

\begin{figure}[h!tp]
	\caption{\label{json_example}Exemplo de estrutura JSON para recomendações.}
	\begin{center}
		\includegraphics[scale=0.75]{images/json_example.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

Em outras palavras, esta seção apresenta o ponto de contato com a API, onde todas as requisições para modificações de recursos são feitas, visando melhorar a precisão das recomendações. Primeiro, é abordado o padrão de nomenclatura dos \textit{endpoints} na seção \ref{endpoints}, de modo a esclarecer de forma geral, toda a gama de possibilidade que o usuário da API tem ao utilizá-la. Em seguida, é apresentado o processo de autenticação na seção \ref{autenticacao}, necessário para que o usuário da API possa executar as requisições.

\subsection{Padrão de \textit{Endpoints}} \label{endpoints}

Toda a comunicação entre o agente das requisições e a API funciona através de \textit{endpoints} que modificam seus respectivos recursos. Recursos esses que são abstrações da base de dados, fazendo com que o agente das requisições possa interferir diretamente na evolução das recomendações, mesmo sem que haja uma interface gráfica. Um exemplo de recurso pode ser visualizado no quadro \ref{resource_example}.

\begin{quadro}[h!tp]

	\caption{\label{resource_example}Exemplo de recurso de \textit{endpoints} para o módulo item.}
	\centering
	\begin{tabular}{|l|l|l|}
	\hline
	\textbf{Método HTTP} & \textit{\textbf{Endpoint}} & \textbf{Descrição}          \\ \hline
	POST                 & /item                      & Cria um novo item           \\ \hline
	GET                  & /item/:item\_id 			  & Retorna um item específico  \\ \hline
	PUT                  & /item/:item\_id            & Altera um item específico   \\ \hline
	DELETE               & /item/:item\_id            & Deleta um item específico   \\ \hline
	GET                  & /item                      & Retorna todos os itens      \\ \hline
	\end{tabular}

	Fonte: O Autor.

\end{quadro}

Analisando o quadro \ref{resource_example}, nota-se que um mesmo \textit{endpoint} pode apontar para diferentes funções, uma vez que o método HTTP que encabeça a requisição também é levado em consideração. Além disso, é importante ressaltar que cada par de \textbf{método HTTP} e \textbf{\textit{endpoint}} correspondem diretamente a um \textbf{controlador} da API, que recebe os parâmetros variáveis da requisição (no quadro \ref{resource_example} representando por \textit{item\_id}) e os repassa aos serviços. Sendo assim, os controladores poderiam ser definidos como as "portas de entrada" da API, direcionando a execução de cada funcionalidade.

Para aumentar o nível de abstração do funcionamento da API, o padrão de \textit{endpoints} utiliza do atributo de identificador único de cada módulo, previamente definido nos metadados de itens, usuários e avaliações, para o acesso a um recurso específico. Dessa forma, o usuário da API pode utilizar os seus próprios identificadores de sua base de dados externa, para acessar os mesmos recursos na base interna da aplicação. O modo de declaração deste atributo e seu tipo de dado esperado podem ser vistos na seção \nameref{analisador:padrao_metadados}. 

\subsection{Autenticação} \label{autenticacao}

Como forma de aumentar a segurança durante as requisições e, principalmente, garantir que apenas os usuários com acesso ao serviço façam requisições, a API conta com um sistema de autenticação via \textit{token}.

Antes da primeira inicialização, o \textit{script} gera um \textit{token} único para o usuário da API, que será posteriormente concatenado com uma palavra secreta nos arquivos de configuração, além da data e hora atuais da requisição de autenticação. O resultado final é um \textit{token} temporário, com validade de até quinze dias, que será utilizado, obrigatoriamente, no cabeçalho de quaisquer requisições aos recursos da API.

Do mesmo modo que o agente das requisições precisa incluir o \textit{token} temporário no cabeçalho das requisições, a API precisa verificar a validade deste \textit{token}. Para que isso seja possível, foi criada uma classe intermediária (\textit{middleware}) que intercepta todas as requisições, exceto a requisição de autenticação. Essa classe, por sua vez, verifica a existência do \textit{token} no cabeçalho da requisição bem como sua validade. Caso o \textit{token} não exista ou não remeta a um usuário de API válido, o \textit{middleware} bloqueia a execução da requisição, retornando uma mensagem de erro e um \textit{status code} igual a \textbf{403} - "\textit{Forbidden}". Um exemplo requisição de autenticação pode ser visto na figura \ref{auth_example}.

\begin{figure}[h!tp]
	\caption{\label{auth_example}Exemplo de autenticação.}
	\begin{center}
		\includegraphics[scale=0.6]{images/auth_example.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

\section{O Analisador de Dados} \label{analisador}

Para tornar possível a geração de recomendações de forma genérica, através dos metadados, foi necessária a construção de um módulo dedicado exclusivamente a este fator. O \textbf{analisador de dados} tem como principal objetivo cruzar as novas informações, repassadas pela interface de comunicação, com os metadados correntes.

Por exemplo, para que um novo item seja adicionado ao conjunto de itens conhecidos e, posteriormente, treinado contra os outros itens, é necessário que o analisador de dados verifique se todos os atributos relevantes para as recomendações estão preenchidos, se os tipos dos campos fornecidos condizem com os tipos especificados nos metadados, etc.

Em síntese, esta seção apresentará os principais componentes do analisador de dados. Primeiro apresentando os padrões utilizados para a orientação a metadados na seção \ref{analisador:padrao_metadados}, em seguida, os modelos gerados pelos metadados e sua utilização em toda a aplicação, aprofundados na seção \ref{analisador:modelos} e, por fim, como é feita a persistência destes dados na seção \ref{analisador:persistencia}.

\subsection{Padrão de Metadados} \label{analisador:padrao_metadados}

Uma vez que não se sabe qual o padrão de JSON a se retornar ao usuário, ou quais os campos relevantes para a geração das recomendações, ou ainda quais sequer são os nomes dos atributos, os metadados são as estruturas, previamente definidas e passíveis de personalização, fornecidas pelo usuário na inicialização da aplicação. Estas estruturas são enviadas através de uma estrutura JSON para os \textit{endpoints} respectivos, divididos em três categorias:

\begin{itemize}
	\item \textbf{Usuários}: Definem os nomes dos atributos, obrigatórios ou não, que compõem o modelo de usuário, os tipos de cada atributo, a quantidade máxima de caracteres, se é recomendável ou não e seu peso. Além disso os metadados de usuários apontam o identificador único do usuário.

	\item \textbf{Itens}: Assim como os usuários, definem os nomes de cada atributo, obrigatórios ou não, do item e suas demais características. Além disso, é definida a exibição de cada atributo do item no retorno das recomendações e seu identificador único.

	\item \textbf{Avaliações}: Definem obrigatoriamente o campo de identificador único do usuário e o campo de identificador único do item, amarrando efetivamente as duas entidades. Além disso, definem o tipo de avaliação que será empregada (binária ou não).
\end{itemize}

Para ilustrar o processo de definição dos metadados, a figura \ref{metadata} mostra um exemplo real dos metadados inciais para o modelo de \textbf{item}. Estes atributos podem ser modificados posteriormente através do mesmo \textit{endpoint} utilizando o método PUT do HTTP. Caso o qualquer atributo sofra posterior alteração, os metadados são salvos com o status \textbf{"\textit{active:false}"}, orientado que o mesmo não é mais válido. Em seguida, um novo conjunto de metadados é criado com o atributo \textbf{"\textit{active:true}"} e as modificações solicitadas pelo usuário.

\begin{figure}[htp]
	\caption{\label{metadata}Exemplo de declaração de metadados para o item.}
	\begin{center}
		\includegraphics[scale=0.8]{images/metadata.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

Analisando a figura \ref{metadata} nota-se um conjunto de chaves pré-definidas para a estrutura declarada. A razão dessas chaves possuírem suas definições \textbf{obrigatórias e pré-definidas} é o fato de que as mesmas moldam todas as outros atributos dinamicamente atribuídos aos modelos de itens, usuários e avaliações, consequentemente moldando o banco de dados. Sendo assim, cada chave da estrutura definida na figura é utilizada como atributo chave para alguma decisão estrutural dentro da API. As chaves definidas na figura possuem as seguintes funcionalidades:

\begin{itemize}
	\item \textbf{\textit{type}}: Fora da chave \textbf{\textit{"attributes"}}, define o tipo do grupo de metadados que correspondem os atributos declarados. Dentro de um atributo, define o tipo do dado ao qual o atributo espera um valor, podendo ser qualquer tipo natural: \textbf{\textit{string}}, \textbf{\textit{integer}}, \textbf{\textit{float}}, etc. Espera um valor do tipo \textbf{\textit{string}}.

	\item \textbf{\textit{attributes}}: Declara a lista de atributos pertencentes ao \textit{type}, neste caso ao item.  Espera um valor do tipo \textbf{\textit{array}}.

	\item \textbf{\textit{name}}: Define o nome de um atributo, o qual será utilizado como chave do atributo no banco de dados e na construção dinâmica do modelo. Espera um valor do tipo \textbf{\textit{string}}.

	\item \textbf{\textit{key}}: Define se o atributo é ou não um identificador único. Será utilizado posteriormente para ligar os usuários a itens e para fazer as consultas dos endpoints.  Espera um valor do tipo \textbf{\textit{boolean}}.

	\item \textbf{\textit{hide}}: Define se o atributo será ou não exibido no JSON de retorno. Espera um valor do tipo \textbf{\textit{boolean}}.

	\item \textbf{\textit{unique}}: Define se o atributo deve ser único na base de dados ou não. Caso o seu valor seja verdadeiro (\textit{true}), o analisador de dados retornará um erro para a requisição, caso este atributo já exista. Espera um valor do tipo \textbf{\textit{boolean}}.

	\item \textbf{\textit{nullable}}: Por padrão, todos os atributos declarados nos metadados serão obrigatórios na inserção de novos registros. Caso este atributo estiver com o valor verdadeiro (\textit{true}), o mesmo torna-se opcional. Espera um valor do tipo \textbf{\textit{boolean}}.

	\item \textbf{\textit{max\_length}}: Declara a quantidade máxima de tamanho/caracteres que o campo suporta. Será utilizada posteriormente para barrar entradas maiores que esse valor no banco de dados. Espera um valor do tipo \textbf{\textit{integer}}.

	\item \textbf{\textit{recommendable}}: Define se o atributo será utilizado como base para as recomendações ou não. Será utilizado pelo motor de recomendações para levar em consideração apenas os atributos que o usuário da API julgar relevantes. Espera um valor do tipo \textbf{\textit{boolean}}.

	\item \textbf{\textit{weight}}: Se o atributo \textbf{\textit{recommendable}} for verdadeiro (\textit{true}), define o a peso do atributo nos cálculos de recomendação. O peso varia de um a dez. Espera um valor do tipo \textbf{\textit{integer}}.
\end{itemize}

Assim que a API toma conhecimento dos metadados, já é possível ao usuário da API preencher o banco de dados com seus usuários, itens e avaliações iniciais.

Por outro lado, a API, antes de persistir os metadados na base, adiciona alguns atributos para facilitar o gerenciamento posterior, dentre eles: um atributo de \textbf{data} para representar a data de inserção, um atributo de \textbf{versão} para identificar a evolução da estrutura e, por fim, um atributo \textbf{\textit{active}} que, se possuir valor verdadeiro, determina qual é grupo de metadados que está atualmente em vigor. Uma linha do tempo dos metadados com as modificações feitas pelo usuário da API pode ser acessada através do endpoint \textbf{/metadata/:metadata\_type/history}.

\subsection{Modelos de Metadados, Itens, Usuários e Avaliações} \label{analisador:modelos}

Para gerenciar o fluxo de dados dentro da API, se fez necessária a criação de modelos encapsuladores, que tem como função abstrair a complexidade da validação, gerenciamento e representação destes dados dinâmicos.

Levando em conta que não se sabe quais serão os atributos de um item, por exemplo, antes do tempo de execução, é necessário que a validação seja feita com base não nos atributos do item, mas sim nos atributos previamente definidos pelos metadados do mesmo. Dessa forma, é possível contrastar o padrão esperado, definido nos metadados, com os dados efetivamente enviados pelo usuário da API.

Levando em consideração os atributos do grupo de metadados apresentados na seção \nameref{analisador:padrao_metadados}, a figura \ref{validation} apresenta um exemplo de validação, feito na linguagem Python, utilizando tais atributos para dinamicamente verificar o padrão do item recebido através de uma requisição do usuário da API. As partes irrelevantes do código foram omitidas para melhor apresentação.

\begin{figure}[h!tp]
	\caption{\label{validation}Validação baseada nos metadados.}
	\begin{center}
		\includegraphics[scale=0.83]{images/python_validation.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

Ao contrário das aplicações comuns, que delegam o trabalho de manter a saúde dos dados para a base de dados, esta estratégia não é viável nesta aplicação devido ao fato da estrutura do banco de dados não só ser dinâmica, como também totalmente customizada pelo usuário da API.

Dessa forma, o trecho de código mostrado na figura \ref{validation}, em conjunto outras classes auxiliares, tem como objetivo garantir que, apenas os dados enviados dentro do padrão descrito no grupo de metadados correspondente, serão persistidos no banco de dados.

Sendo assim, a lógica da figura pode ser descrita da seguinte forma: primeiro a aplicação percorre todos os atributos dos metadados correspondente. Para cada atributo descrito nos metadados, a aplicação testa se este atributo, caso seja obrigatório (\textbf{\textit{nullable:false}}), está contido no JSON recebido pelo \textit{endpoint}. Se o atributo obrigatório não existir, a aplicação retorna um JSON de erro com o \textit{status code} igual a \textbf{400}, indicando uma \textbf{\textit{bad request}}. Caso o atributo exista, a aplicação testa se o tipo do dado recebido condiz com o tipo declarado nos metadados (\textbf{\textit{type}}). Uma vez que todos os atributos obrigatórios são satisfeitos pelo JSON recebido, a aplicação o persiste na base de dados.

Para ilustrar o processo, a figura \ref{validation_schema} demonstra um exemplo do fluxo interno do \textbf{analisador de dados}, desde o recebimento da informação, até a persistência e posterior retorno da mesma. O código completo dos modelos de dados pode ser visto no apêndice \nameref{source_code}.

\begin{figure}[h!tp]
	\caption{\label{validation_schema}Esquema do fluxo do analisador de dados.}
	\begin{center}
		\includegraphics[scale=0.8]{images/validation.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

Representando o fluxo de modificação dos dados de um item específico, nota-se na figura \ref{validation_schema}, que o analisador de dados recebe as devidas requisições através da interface de comunicação, transformando-as em modelos dos recursos. Assim que os modelos são construídos, são carregados da base de dados os metadados vigentes, utilizados posteriormente no contraste e validação destes modelos. Caso o modelo de item, representação abstrata da requisição do usuário da API, seja válido, o mesmo é persistido na base de dados e, posteriormente, enviado como retorno. Caso o item não seja válido, ao invés de persisti-lo na base, uma mensagem de erro é enviada como retorno ao usuário da API.

Todavia, em caso de sucesso na persistência, antes de efetivamente retornar o \textit{feedback} ao agente da requisição, o analisador de dados constrói a estrutura de retorno a partir dos atributos dos metadados em vigor. O atributo declarado como identificador único (\textbf{\textit{key:true}}) nos metadados é obrigatoriamente adicionado na estrutura de retorno, uma vez que é utilizado como parâmetro base em todos os \textit{endpoints} relacionados. Além disso, o atributo \textbf{\textit{hide}} define se o atributo existente será exibido ou não no JSON de retorno.

\subsection{Persistência} \label{analisador:persistencia}

A base de um sistema de recomendação é o conhecimento prévio, uma vez que, independente da métrica ou método utilizados, todos utilizam do cruzamento de informações conhecidas para gerar predições (vide seção \ref{recommender_systems}). Dessa forma, é necessário que alguma estratégia eficiente de armazenamento e consulta seja utilizada, tendo em vista que o cruzamento dessas informações pode gerar matrizes excedendo milhões linhas e colunas \cite{gomez2016netflix}.

Visando utilizar uma estratégia de persistência que se destacasse no processamento de grandes conjuntos de dados, ponto essencial para boas recomendações, a API implementa uma persistência utilizando um banco de dados não relacional (NoSQL) orientado a documentos \cite{leavitt2010will}, que além de proficiente no manejo dos dados, também persiste os mesmos em estruturas baseadas em JSON, como apresentado por \citeonline{padhy2011rdbms}.

Devido ao JSON ser o padrão escolhido para a estrutura de dados da aplicação, a similaridade entre o documento armazenado no banco de dados e o JSON de retorno ao usuário da API é muito pequena, reduzindo o nível de complexidade como um todo. Além disso, é permitida a inserção de documentos dinâmicos, sem um padrão previamente definidos em tabelas e campos, sendo possível inserir novos atributos em itens, usuários e avaliações apenas declarando-os nos metadados, sem a necessidade de modificar a estrutura da base de dados.

A fim de abstrair este processo para os outras partes da aplicação, foram criadas serviços de persitência para cada módulo existente, responsáveis por administrar toda a comunicação com o banco de dados. Tais serviços são utilizados tanto pelo \textbf{analisador de dados} quando pelo \textbf{motor de recomendações}, seja para a persistência de novas recomendações recém geradas ou para novos itens enviados pelo usuário da API através da interface de comunicação. A figura \ref{persistence} demonstra o processo de construção dinâmica do item através do modelo e sua persistência no banco de dados.

\begin{figure}[h!tp]
	\caption{\label{persistence}Esquema do serviço de persistência.}
	\begin{center}
		\includegraphics[scale=0.83]{images/persistence.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

Como apresentado na figura \ref{persistence}, o serviço de persistência recebe um modelo, previamente criado e validado pelo \textbf{analisador de dados}. Este modelo será contrastado com os metadados vigentes para geração dinâmica de um documento no formato necessário para sua inserção no banco de dados. Assim como nos \textit{endpoints} da interface de comunicação, os serviços de persitência usam como parâmetros para administração de documentos específicos o identificador único (\textbf{\textit{key:true}}) declarado nos metadados, gerando documentos com base neste identificador.

Além da persistência do modeo recebido, o serviço de persistência também é encarregado de notificar o motor de recomendações de quaisquer modificações ou adições aos documentos existentes. Esta notificação é necessária para que o motor de recomendações saiba quando é necessário treinar novos documentos recém adicionados, ou quando treinar novamente documentos que mudaram seu estado. O processo de recebimento das notificações e treinamento da base pode ser visto na seção \nameref{motor}.

\section{O Motor de Recomendações} \label{motor}

Toda a estrutura acima descrita tem como objetivo possibilitar o funcionamento do motor de recomendações, fornecendo os dados necessários para a geração das matrizes de predição. O motor de recomendações, por sua vez, tem como objetivo efetivamente gerar as recomendações para quaisquer usuários ou itens, levando em consideração o padrão de gostos do usuário, o conteúdo do item e a relação entre ambos.

Do mesmo modo que o analisador de dados, o motor de recomendações faz uso dos modelos de usuários, itens e avaliações visando obter informações geradas dinamicamente com o uso dos metadados. Dentre as informações relevantes para o motor de recomendações estão:

\begin{itemize}
	\item \textbf{Atributos recomendáveis}: Os atributos marcados com a \textit{tag} \textbf{\textit{recommendable:true}} mapeam quais atributos devem ser levados em consideração pelos algoritmos.

	\item \textbf{Peso dos atributos}: Os atributos marcados com a \textit{tag} \textbf{\textit{weight}} mapeam quais atributos, além de recomendáveis, recebem um peso diferenciado para os algoritmos, maximizando o nível de personalização.

	\item \textbf{Identificadores únicos}: Os atributos marcados com a \textit{tag} \textbf{\textit{key:true}} identificam quais informações serão utilizadas como identificadores de itens e usuários durante a execução dos algoritmos, permitindo sua correta persistência, além de manter a integridade das recomendações. Além disso, permitem identificar quais usuários avaliaram quais itens, informação essencial para a recomendação colaborativa.

	\item \textbf{Valor da avaliação}: Os atributos dos metadados de avaliação marcados com a \textit{tag} \textbf{\textit{rating}} fornecem o valor de cada avaliação do usuário aos itens, permitindo a identificação do padrão de gostos do usuário, essencial para o cálculo da similaridade entre os itens.
\end{itemize}

De posse destes dados persistidos na base, o motor de recomendações consegue cruzá-los a fim de obter duas matrizes: a matriz de nível de similaridade entre itens e, posteriormente, a matriz de itens de maior similaridades não avaliados para cada usuário. Essas matrizes são posteriormente desmembradas em rakings de itens e persistidos em cada usuário e item, com seus itens de maior similaridade, em outras palavras, suas recomendações.

Como forma de recomendação será utilizado o método híbrido, composto dos métodos \textbf{baseado em conteúdo} e \textbf{filtragem colaborativa}, escalonando através do método com melhor precisão momentânea. Dessa forma é possível atender qualquer tipo de metadado, fornecendo recomendações independente do número de usuários, itens e avaliações na base de dados.

Em um primeiro momento, a API utilizará o método baseado em conteúdo para fornecer as recomendações e predições, uma vez que poucos itens estarão avaliados e o método colaborativo não terá modelos de usuários suficientes. Ao passo que as métricas de relações entre usuários e quantidade de modelos processados sejam supridas, a API passará a utilizar o método de filtragem colaborativa, unindo os resultados com os maiores níveis de similaridades, levando em conta as duas diferentes abordagens.

Visando salientar de forma concisa o processo de recomendações, centro deste trabalho, esta seção está divida em três partes. Primeiramente é abordada a interação entre o motor de recomendações e as demais funcionalidades da API, o modo como são notificadas as mudanças e o assincronismo entre as requisições do usuário e a geração das recomendações. Em seguida, são detalhados os dois módulos que compõem o motor de recomendações: o \textbf{motor de conteúdo} e o \textbf{motor colaborativo}, abordando suas diferenças e peculiaridades.

\subsection{Escalonador} \label{motor:async}

Tendo em vista que o objetivo desta aplicação é fornecer recomendações híbridas, é necessária a intervenção de algum mecanismo que faça a escolha entre quais recomendações entregar ao usuário da API, levando em consideração os resultados de ambos os motores. Este mecanismo escalonador, responsável pelo gerenciamento entre os motores de recomendação e o resto da aplicação, permite que apenas as recomendações com os maiores níveis de similaridade sejam respondidos a interface de comunicação.

Para tornar possível a escolha dinâmica de recomendações, o escalonador faz requisições paralelas a ambos os motores de recomendação, aguardando suas posteriores respostas e, assim que as recebe, fundindo as melhores recomendações em um pacote que será persistido no banco de dados. Estas requisições paralelas são gerenciadas internamente por \textit{\textbf{workers}}, que atentam ao início e fim dos procedimentos paralelos de recomendação. O esquema de funcionamento do escalonador pode ser visto na figura \ref{scheduler}.

\begin{figure}[h!tp]
	\caption{\label{scheduler}Funcionamento do escalonador de recomendações.}
	\begin{center}
		\includegraphics[scale=0.8]{images/scheduler.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

Analisando a figura \ref{scheduler}, nota-se que o escalonador é a base que sustenta a comunicação entre o serviço de persistência e os motores de recomendação, além de transformar as notificações de mudança do estado dos dados em requisições paralelas para treinamento dos itens e usuários.

Além disso, a estratégia para fusão das recomendações poode ser descrita da seguinte forma: o escalonador requisita aos \textbf{\textit{workers}} que iniciem o processo de treinamento para ambos os motores de recomendação. Ao término de ambos, o escalonador analisa as recomendações retornadas para cada item, caso seja um treinamento de toda a base de dados, ou as recomendações do item em questão, caso seja o treinamento da mudança de um item em específico, fundindo-as em uma lista única. Após a fusão de recomendações, o escalonador remove as repetições e, posteriormente, persiste as $k$ recomendações com maior nível de similaridade no banco de dados.

Por fim basta a interface de comunicação, em um momento futuro onde o usuário da API requisita recomendações, notificar o serviço de persistência para que o mesmo requisite a lista de itens similares ao usuário/item em questão (\textbf{\textit{similar}}), sem a necessidade de um processamento em tempo real, uma vez que as recomendações já foram persistidas anteriormente.

\subsection{Motor de Conteúdo} \label{motor:conteudo}

Conforme abordado na seção \nameref{recs:content_based}, os sistemas de recomendação baseados em conteúdo analisam o conteúdo de itens previamente avaliados pelo usuário. Esta seção aborda a implementação deste tipo de sistema recomendador no contexto da aplicação, dissecando os princiais tópicos relacionados a sistemas baseados em conteúdo e como foram implementados de modo a serem personalizados através dos metadados.

Para que seja possível fornecer recomendações de itens baseando-se em seu conteúdo de forma dinâmica, assim que o motor de recomendações é notificado de uma mudança relevante no estado dos dados, como apresentado na seção \nameref{motor:async}, uma série de passos são executados. Este processo pós-notificação pode ser divido em cinco partes:

\begin{enumerate}
	\item \textbf{Obtenção das informações}: carrega uma lista de todos os itens com os atributos a serem processados (\textbf{\textit{recommendable}}) declarados nos metadados.

	\item \textbf{Cálculo da similaridade}: para cada item $I_{m}$ obtido, gera uma matriz de $[m, n]$ itens com o grau de similaridade entre o item corrente e os demais.

	\item \textbf{Cálculo da proximidade}: para cada item $I_n$ da matriz de similaridades, calcula a distância de coseno entre o item $I_n$ e cada item da lista $\lbrace S_{0}$, ..., $S_{j} \rbrace$, sendo $S$ um item similar a $I_{n}$.

	\item \textbf{Persistência por proximidade}: ordena a lista de distâncias, resultante de cada item $I_{n}$, da menor distância para a maior, persistindo um ranking dos cinquenta itens mais próximos como similares do item $I_{n}$ na base de dados.

	\item \textbf{Obtenção das recomendações}: consulta a base de dados para obter os $k$ itens da lista de similares para o item $I_{n}$ e os retorna ao usuário da API.
\end{enumerate}

Como resultado final do processamento feito pelo \textbf{motor de conteúdo}, as recomendações não são retornadas ao usuário da API, mas sim persistidas no banco de dados. Isso ocorre pois o tempo de retorno se tornaria muito alto, devido a quantidade de processos a serem feitos, além do principal fato de que as notificações de mudança são recebidas pelo motor em momentos diferentes das requisições de recomendação do usuário da API. O processo de geração das recomendações, abstraído da interação com o escalonador, pode ser visto na figura \ref{content_engine}. 

\begin{figure}[h!tp]
	\caption{\label{content_engine}Funcionamento do motor de conteúdo.}
	\begin{center}
		\includegraphics[scale=0.8]{images/content_engine.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

Sendo assim, o processo do motor de conteúdo pode ser definido da seguinte maneira: primeiramente o motor de conteúdo recebe uma requisição do escalonador para gerar novas recomendações ao item, devido a um novo item inserido na base ou uma alteração nas informações do mesmo. Uma vez notificada a mudança, o motor requisita ao serviço de persitência a \textbf{obtenção das informações recomendáveis}.

Para satisfazer as necessidades do motor de recomendações, o serviço de persistência de itens requisita aos metadados quais são os \textbf{atributos recomendáveis vigentes} e, a partir destes, obtém os dados decorrentes do banco de dados. Uma vez em posse destes dados, entrega-os em forma de lista.

Assim que o motor de conteúdo obtém a lista de itens, os mesmos são percorridos um a um, calculando o nível de similaridade do item em questão em contraste com os demais. O nível de similaridade é calculado através do algoritmo \textbf{TF-IDF}, abordado por \citeonline{pazzani2007content} e \citeonline{leskovec2014mining}. Este algoritmo calcula a \textbf{frequência do termo–inverso da frequência nos documentos}, ideal neste caso para transformar campos textuais em pesos numéricos, multiplicados posteriormente pelo peso de cada atributo recomendável nos metadados, gerando finalmente o grau de similaridade.

Por fim, de posse da matriz de similaridades, o motor de conteúdo percorre a mesma, item a item, calculando o grau de distância entre o item em questão e os demais itens da lista. A distância é calculada através do algoritmo da \textbf{similaridade de coseno}, que mede o espaço produto do coseno aplicado as similaridades. Após o processamento, os $k$ itens de menor distância são persistidos no banco de dados pelo serviço de persistência de itens, que atribui a \textit{tag} \textbf{\textit{similar}} a lista de itens persistidos.

\subsection{Motor Colaborativo} \label{motor:colaborativo}

Assim como o motor de conteúdo, o motor colaborativo opera sobre matrizes, com exceção de que, ao invés de matrizes que contrastam itens, o motor gera matrizes que contrastam usuários e itens. Para isso, são necessários registros que relacionem usuários e itens a um pesdo dado, as avaliações. Estas avaliações podem ser binárias (\textit{like}/\textit{unlike}) ou enumeradas, como avaliações de zero a cinco estrelas, por exemplo.

Recomendações utilizando o método colaborativo, como apresentadas na seção \nameref{recs:collaborative_based}, podem ser orientadas a usuário ou a item. Como forma de compensar o motor de conteúdo, que se baseia inteiramente em itens, o método empregado neste motor será orientado a usuário. Sendo assim, o método de recomendação colaborativa orientado a usuário implementado nesta aplicação pode ser dividido em seis partes:

\begin{enumerate}
	\item \textbf{Obtenção das avaliações}: O motor colaborativo requisita ao serviço de persistência os registros válidos de recomendações de usuários a itens.

	\item \textbf{Construção da matriz de intersecções}: para acada usuário $U_{n}$, identifica as intersecções, ou seja, itens avaliados por ambos os usuários em questão, gerando uma matriz de intersecções.

	\item \textbf{Construção da matriz de similaridades}: a partir da matriz de intersecções, para cada usuário $U_{n}$ calcula a \textbf{correlação de pearson} entre o usuário $U_{n}$ e os usuários $\lbrace S_{0}$, ..., $S_{j} \rbrace$ pertencentes a lista de intersecções, utilizando como base as avaliações de ambos sobre o item.

	\item \textbf{Cálculo da distância}: após a construção da matriz de similaridades, para cada usuário $U_{n}$ pertencente a matriz, calcula a \textbf{distância euclidiana} entre o usuário $U_{n}$ e os usuários $\lbrace S_{0}$, ..., $S_{j} \rbrace$ considerados similares na matriz, gerando uma matriz de usuários mais próximos.

	\item \textbf{Persistência por proximidade}: para cada usuário $U_{n}$ da matriz de proximidade, persiste os itens dos $k$ usuários mais próximos no banco de dados como recomendações ao usuário em questão.

	\item \textbf{Obtenção das recomendações}: consulta a base de dados para obter os $k$ itens da lista de similares para o usuário $U_{n}$ e os retorna ao usuário da API.
\end{enumerate}

A medida que o número de avaliações aumenta, em corelação com o tempo de vida da aplicação, as recomendações do motor de colaraboração tendem a ser mais precisas, uma vez que fazem uso da própria manifestação dos usuários para definir as similaridades. A interação do motor colaborativo com o resto da aplicação pode ser visto na figura \ref{collaborative_engine}.

\begin{figure}[h!tp]
	\caption{\label{collaborative_engine}Funcionamento do motor colaborativo.}
	\begin{center}
		\includegraphics[scale=0.8]{images/collaborative_engine.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

Analisando a figura \ref{collaborative_engine}, nota-se que o fluxo de funcionamento do motor colaborativo se assemelha muito ao motor de conteúdo. O ponto de diferença está no conteúdo das matrizes, onde no motor de conteúdo são preenchidas com itens e suas similaridades, já no motor colaborativo são preenchidas com as intersecções de avaliações de usuários e, posteriormente, com a similaridade entre eles.

\section{Testes e Implementação} \label{testes}

Durante o processo de desenvolvimento do protótipo desta aplicação, foi necessária a utilização de um grupo de dados de teste não só nos padrões especificados pela API, mas também coerente com sua semântica de relações. Dessa forma, os testes do funcionamento das recomendações foram executados com a utilização de uma base real de usuários, itens e avaliações, contendo um volume de dados suficiente para que os objetivos deste trabalho fossem assegurados.

A base de dados em questão é a do projeto \textbf{MovieLens}, proposto por \citeonline{harper2016movielens}, comumente utilizada para aplicações com este fim devido ao fato de possuir inúmeras opções de tamanhos diferentes, preenchidas com dados retirados de ambientes de produção. Além disso, a base de testes acima descrita, foi amplamente utilizada para testar a assertividade de algoritmos durante o \textbf{NetflixPrize}, evento promovido pela empresa \textbf{Netflix} para eleger os algoritmos de recomendações mais assertivos \cite{bennett2007netflix}.

Acerca dos testes e implementações efetuadas, esta seção disseca tal processo em quatro partes. Primeiro são apresentadas as implementações referentes ao preenchimento do conjunto teste de dados e seus resultados. Logo após, é apresentado o processo de documentação automática, implementado visando a contribuição da comunidade. Em seguida, é apresentada a composição de cada um dos \textit{scripts} que efetuam a instalação da API e sua inicalização, além da atualização de eventuais dependências do projeto. Por fim, são abordadas, de forma mais específica, as tecnologias utilizadas durante o desenvolvimento desta aplicação.

\subsection{\textit{Seed} de Dados} \label{seed}

Como forma de automatizar o processo de geração dos dados de teste da aplicação, foi implementado um \textit{script}, podendo ser chamado pelo usuário da API, com a função de fazer o \textit{download} do conjunto de dados do projeto \textbf{MovieLens}, configurar os metadados correspondentes e fazer a persistência das informações. Este \textit{script}, executado pela linha de comando do sistema operacional e intitulado \textbf{seed.sh}, visa facilitar o processo de primeira inicialização da aplicação, atraindo novos usuários e aumentando o número de colaboradores no projeto.

Além disso, o \textit{seed} de dados proporciona um teste, quase que imediato, do funcionamento completo da API. Ao passo que o \textit{script} finaliza sua execução, o usuário da API já pode fazer requisições de recomendações, visualizando de forma simples e concisa o potencial da mesma. O processo de \textit{seed} de dados pode ser dividido em quatro passos:

\begin{enumerate}
	\item \textbf{\textit{Download} do conjunto de dados}: o \textit{script} executa o \textit{download} do conjunto de dados com aproximadamente um milhão de registros (itens, usuários e avaliações).

	\item \textbf{Conversão dos dados para o padrão da API}: a classe conversora do \textit{seeder} de dados converte o padrão recebido pelo padrão utilizado na API (JSON).

	\item \textbf{Persistência dos dados}: após a conversão , a classe conversora invoca o serviço de persistência para persistir toda o conjunto de dados de uma só vez.

	\item \textbf{Configuração dos metadados e treinamento da base}: a classe conversora configura os primeiros metadados de acordo com o padrão recebido e os persiste na base através do serviço de persistência. Ao ser notificado da alteração no estado da base, o motor de recomendações treina o conjunto recebido.
\end{enumerate}

Caso o usuário da API queira preencher a aplicação com seus próprios dados, o mesmo deve executar o \textit{script} de inicalização, fazendo com que os dados de exemplo sejam removidos e as configurações redefinidas. O processo de inicialização da API e as configurações são abordadas na seção \nameref{init}.

\subsection{Instalação e Inicialização} \label{init}

Além da automatização na criação de dados de exemplo, apresentada na seção \nameref{seed}, foram implementados outros \textit{scripts} auxiliares de instalação, inicalização e atualização de dependências, nomeados \textbf{setup.sh}, \textbf{start.sh} e \textbf{update\_dependencies.sh} respectivamente. Todos estres \textit{scripts}, contidos na pasta \textit{"scripts"} da aplicação, visam aumentar a simplicidade no uso da API e, consequentemente possibilitar a utilização pela comunidade em geral.

O \textit{script} de instalação (\textbf{setup.sh}) tem como função instalar todas as dependências iniciais do projeto, além de configurar completamente o ambiente virtual no qual a aplicação é executada. Este ambiente virtual serve para que o escopo das dependências e dos pacotes instalados pelo \textit{script} de instalação não poluam a máquina do usuário da API.

Além disso, o \textit{script} de inicialização requisita algumas informações necessárias para a configuração inicial da aplicação, tais como o nome, usuário e senha do banco de dados e a palavra secreta utilizada na autenticação. Estas configurações guiam o funcionamento da API como um todo e podem ser modificados a qualquer momento no arquivo de variáveis de ambiente (\textbf{env.py}).

O \textit{script} de inicalização (\textbf{start.sh}) tem como função inicializar o serviço \textit{web} da aplicação, ativando o ambiente virtual criado pelo \textit{script} de instalação e executando o arquivo que inicializa a API. Assim que iniciada, a aplicação é acessível através de um endereço IP e porta específicos, configuráveis através do arquivo de variáveis de ambiente (\textbf{env.py}).

Em caso de adição ou modificação na versão de alguma das dependências da aplicação, o \textit{script} \textbf{update\_dependencies.sh} tem como objetivo atualizar as dependências já listadas anteriormente, além de instalar novas dependências recém adicionadas. As dependências do projeto podem ser adicionadas no arquivo de requerimentos da aplicação (\textbf{requirements.txt}).

\subsection{Documentação}

Durante boa parte do processo de desenvolvimento da aplicação, foi implementada a documentação dos módulos, funções e métodos escritos, visando facilitar a manutenção futura da aplicação e a contribuição da comunidade. Tais trechos de código documentados são dinamicamente carregados em uma documentação automática, gerada a partir de um \textit{template} que converte os comentários acima do código, os parâmetros de entrada e os tipos de retorno para itens da documentação. Um exemplo de página gerada pela documentação pode ser visto na figura \ref{docs}.

\begin{figure}[h!tp]
	\caption{\label{docs}Documentação automática da API.}
	\begin{center}
		\includegraphics[scale=0.55]{images/docs.png}
	\end{center}
	\hspace{5.5cm}{Fonte: O Autor.}
\end{figure}

A documentação conta com toda a hierarquia correspondente a estrutura da API, deixando visível ao usuário a estrutura empregada e a localização de cada classe e módulo implementados. Além disso, cada módulo documentado possui uma breve descrição das suas funcionalidades. Nas classes de cada módulo são especificados os parâmetros de entrada de cada método, além do tipo de dado esperado e uma descrição do retorno. Se preferir, o usuário pode utilizar um campo de pesquisa para encontrar o método ou módulo desejado.

\subsection{Tecnologias Utilizadas} \label{tecnologias}

Para tornar possível a implementação desta aplicação em tempo hábil, foram empregadas várias tecnologias, escolhidas de modo a fomentar a utilização pela comunidade atual de desenolvedores e a iniciativa \textit{open-source}. O quadro \ref{technologies} apresenta as principais tecnologias utilizadas para a execução deste trabalho e a suas respectivas categorias.

\begin{quadro}[htp]

	\caption{\label{technologies}Tecnologias utilizadas durante a implementação.}
	\centering
	\begin{tabular}{|l|l|}
	\hline
	\textbf{Categoria} 			& \textbf{Tecnologia}   \\ \hline
	Sistema operacional 		& Linux Ubuntu LTS      \\ \hline
	Banco de dados 		   		& MongoDB  				\\ \hline
	Linguagens de programação   & Python e Shell script \\ \hline
	Controle de versão          & Github   				\\ \hline
	Framework de API        	& Flask      			\\ \hline
	Framework de persistência 	& PyMongo 				\\ \hline
	Gerenciador de dependências & Conda 				\\ \hline
	Ferramenta de testes		& Postman				\\ \hline
	Documentação automática		& Sphinx				\\ \hline
	\end{tabular}

	Fonte: O Autor.

\end{quadro}

Visando maximizar a legibilidade e a simplicidade do código fonte, foi utilizada a linguagem \textbf{Python} como base para toda a aplicação. Além disso, a escolha da linguagem Python também se dá pelo fato de existirem módulos de \textit{machine learning} amplamente utilizados em aplicações deste gênero pela comunidade de desenvolvedores Python. Entre eles o \textbf{SciKit}, proposto por \citeonline{pedregosa2011scikit} e utilizado nesta aplicação, equilibrando de forma eficiente o desempenho e a abstração de certos processos.

Como forma de complementar a escolha de legibilidade e desempenho através da linguagem Python, o banco de dados utilizado pela aplicação é o \textbf{MongoDB}. Tal banco de dados foi escolhido devido a sua escalabilidade com grandes volumes de dados e seu tempo de consulta superior aos bancos relacionais. Além disso, a orientação a documentos BSON, inspirados no padrão JSON, facilitaram e muito a comunicação entre banco de dados e aplicação \cite{chodorow2013mongodb}.

Os \textit{scripts} utilizados para automatização, apresentados da seção \nameref{init}, foram escritos na linguagem \textbf{Shell Script}, tendo sua execução pelo \textit{shell} do sistema operacional \textbf{Linux Ubuntu}. Por hora, estes \textit{scripts} apenas são suportados por este sistema operacional e seus derivados.

Para armazenamento e controle de versão do código foi utilizado o \textbf{Github}, ferramenta aberta e colaborativa de repositórios de versão, comumente utilizada pela comunidade. Além do controle de versão, a ferramenta permite que outros desenvolvedores ramifiquem esta aplicações a sua maneira, disseminando a utilização desta API, um dos objetivos deste trabalho \cite{dabbish2012social}.

É importante ressaltar que todas as ferramentas utilizadas durante a execução deste trabalho são de código aberto/livre, escolhidas para fomentar a utilização da aplicação, através de ferramentas já conhecidas e amplamente utilizadas pela comunidade, tais como \textbf{Github}, \textbf{Python}, \textbf{MongoDB}, etc.

%
%--------- FIM API------------
%

\chapter{RESULTADOS E DISCUSSÃO}

Após a implementação de todas as funcionalidades descritas ao longo deste trabalho, todos os objetivos inicialmente traçados foram atingidos. A aplicação gera, de forma híbrida, recomendações a usuários e itens, levando em consideração quaisquer atributos e pesos definidos pelo usuário, além da possibilidade de personalização completa da estrutura de envio e retorno dos dados.

Também é possível acessar a documentação da aplicação, contendo todos os módulos de forma hierárquica e organizada, visando facilitar o compartilhamento futuro com a comunidade. Esta documentação, anexa a todo o código fonte da aplicação, está acessível através do repositório da aplicação no Github: \url{github.com/iurykrieger96/morpy}.

O protótipo da API resultante deste trabalho foi denominada \textbf{MORPY} - \textit{\textbf{M}etadata \textbf{O}riented \textbf{R}ecommendations for \textbf{PY}ton}, visando resumir todas as principais funcionalidades e diferenciais da mesma em um acrônimo.

No entanto, mesmo com os objetivos principais atingidos, trabalhos pendentes precisam ser efetuados para assegurar melhoras de performance e usabilidade da aplicação. Como trabalhos futuros a serem efetuados podem ser listados os seguintes:

\begin{itemize}
	\item O término do processo de documentação nos módulos faltantes;

	\item A utilização de \textit{machine learning} nao só na recomendação de itens mas também na configuração dos metadados, encontrando o melhor conjunto de itens para serem levados em consideração pelo motor de recomendações;

	\item A otimização do processo executado pelo motor de recomendações, fazendo com que processe as matrizes de similaridade e distância utilizando a \textbf{GPU}.

	\item A implementação de autenticação via \textit{token} utilizando um padrão mais seguro que o atual.

	\item O desenvolvimento de uma página de apresentação da aplicação, agregando uma descrição das funcionalidades da API, sua documentação e um link para o Github.
\end{itemize}

\chapter{CONSIDERAÇÕES FINAIS}

Devido ao grande número de implementações dos sistemas de recomendação nas mais diversas áreas que aqui foram apresentadas, torna-se notável a vasta gama de aplicações das técnicas e, mais do que isso, a necessidade de um serviço multipropósito desprendido do uso de linguagens de programação específicas.

A aplicação desenvolvida supre as deficiências apontadas no capítulo \ref{intro}, alinhando as soluções desenvolvidas com os objetivos propostos na seção \nameref{objectives}. Desta forma, esta aplicação pode servir não só como uma alternativa \textit{open-source} aos sistemas de recomendação, mas também como uma tecnologia de utilização simples para futuros estudos na área.

Além disso, é importante ressaltar a preocupação ao longo de todo o processo com o desempenho geral da API, a qualidade da documentação gerada e, principalmente, a qualidade das recomendações. Visando ampla utilização, esta API tem um poder de personalização superior ao visto nos outros trabalhos apresentados na seção \nameref{related_work}, sendo este um diferencial para os usuários. Este diferencial também proporciona algumas vantagens, tais como a escolha de quais atributos serão utilizados pelo sistema recomendados e, posteriormente, qual estrutura será retornada ao usuário.

Não menos importante do que a qualidade das recomendações, está a orientação a metadados, ponto chave durante o desenvolvimento e utilização da aplicação. A escolha de tornar toda a parte central da aplicação personalizável é de grande valhia para listagem de inúmeras possibilidades diferentes de uso e, consequentemente, inúmeros utilizadores em potencial.

Por fim, a aplicação possui seus pontos de melhora, a fim de torná-la cada vez mais precisa nas recomendações e simples ao usuário final.

\postextual

\bibliography{referencias}

\begin{apendicesenv}

	\chapter{Código Fonte da API} \label{source_code}

	O módulo \textbf{app.py} é responsável por declarar todos os \textit{endpoints} (recursos) da interface de comunicação que estaŕão acessíveis pelo usuário da API.

	\lstinputlisting[language=Python, style=custompython,firstline=13]{appendix/app/app.py}

	\section{Metadados}

	\lstinputlisting[language=Python, style=custompython, firstline=5]{appendix/app/api/metadata/UserMetadata.py}

	\lstinputlisting[language=Python, style=custompython, firstline=5]{appendix/app/api/metadata/ItemMetadata.py}

	\lstinputlisting[language=Python, style=custompython, firstline=5]{appendix/app/api/metadata/RatingMetadata.py}

	\section{Modelos de Estruturas}

	\lstinputlisting[language=Python, style=custompython, firstline=7]{appendix/app/api/models/UserModel.py}

	\lstinputlisting[language=Python, style=custompython, firstline=8]{appendix/app/api/models/ItemModel.py}

	\lstinputlisting[language=Python, style=custompython, firstline=8]{appendix/app/api/models/RatingModel.py}

	\section{Recursos de \textit{endpoints}} \label{endpoint_resources}

	\lstinputlisting[language=Python, style=custompython,firstline=10]{appendix/app/api/resources/user.py}

	\lstinputlisting[language=Python, style=custompython,firstline=11]{appendix/app/api/resources/item.py}

	\lstinputlisting[language=Python, style=custompython, firstline=10]{appendix/app/api/resources/rating.py}

	\lstinputlisting[language=Python, style=custompython, firstline=7]{appendix/app/api/resources/recommend.py}

	\lstinputlisting[language=Python, style=custompython, firstline=12]{appendix/app/api/resources/train.py}

	\lstinputlisting[language=Python, style=custompython, firstline=7]{appendix/app/api/resources/auth.py}

	\lstinputlisting[language=Python, style=custompython, firstline=11]{appendix/app/api/resources/metadata.py}

	\section{Serviços de Persistência} \label{services}

	\lstinputlisting[language=Python, style=custompython, firstline=5]{appendix/app/api/services/ItemMetadataService.py}

	\lstinputlisting[language=Python, style=custompython, firstline=6]{appendix/app/api/services/ItemService.py}

	\lstinputlisting[language=Python, style=custompython, firstline=5]{appendix/app/api/services/RatingMetadataService.py}

	\lstinputlisting[language=Python, style=custompython, firstline=5]{appendix/app/api/services/RatingService.py}

	\lstinputlisting[language=Python, style=custompython, firstline=5]{appendix/app/api/services/UserMetadataService.py}

	\lstinputlisting[language=Python, style=custompython, firstline=5]{appendix/app/api/services/UserService.py}

	\lstinputlisting[language=Python, style=custompython, firstline=7]{appendix/app/api/services/RecommenderService.py}

	\section{Motores de Recomendação}

	\lstinputlisting[language=Python, style=custompython, firstline=1]{appendix/app/api/engines/metrics.py}

	\lstinputlisting[language=Python, style=custompython, firstline=10]{appendix/app/api/engines/ContentEngine.py}

	\lstinputlisting[language=Python, style=custompython, firstline=12]{appendix/app/api/engines/CollaborativeEngine.py}
\end{apendicesenv}

\end{document}